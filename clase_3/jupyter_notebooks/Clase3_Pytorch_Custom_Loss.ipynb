{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6hnAb_E0gZFA"
      },
      "source": [
        "# Aprendizaje Profundo - Clase 3  - Custom Loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "TUEjdowba98t"
      },
      "outputs": [],
      "source": [
        "# Importo librer√≠as\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fVMKJ1DihXiv"
      },
      "source": [
        "## Cargamos el dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "dF9wgHw5jTW8"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/drive/MyDrive/Trabajo AP/Material/class_7_wine_dataset_v2.csv'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32md:\\Users\\juanp_schamun\\Documents\\GitRepositories\\CEIA\\aprendizaje_profundo\\clase_3\\jupyter_notebooks\\Clase3_Pytorch_Custom_Loss.ipynb Cell 4\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Users/juanp_schamun/Documents/GitRepositories/CEIA/aprendizaje_profundo/clase_3/jupyter_notebooks/Clase3_Pytorch_Custom_Loss.ipynb#W3sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Carga del dataset\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Users/juanp_schamun/Documents/GitRepositories/CEIA/aprendizaje_profundo/clase_3/jupyter_notebooks/Clase3_Pytorch_Custom_Loss.ipynb#W3sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m\"\u001b[39;49m\u001b[39m/content/drive/MyDrive/Trabajo AP/Material/class_7_wine_dataset_v2.csv\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
            "File \u001b[1;32md:\\Users\\juanp_schamun\\Documents\\GitRepositories\\CEIA\\aprendizaje_profundo\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    899\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    900\u001b[0m     dialect,\n\u001b[0;32m    901\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    908\u001b[0m     dtype_backend\u001b[39m=\u001b[39mdtype_backend,\n\u001b[0;32m    909\u001b[0m )\n\u001b[0;32m    910\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 912\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
            "File \u001b[1;32md:\\Users\\juanp_schamun\\Documents\\GitRepositories\\CEIA\\aprendizaje_profundo\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    574\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m    576\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 577\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m    579\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[0;32m    580\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
            "File \u001b[1;32md:\\Users\\juanp_schamun\\Documents\\GitRepositories\\CEIA\\aprendizaje_profundo\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1404\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m   1406\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1407\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
            "File \u001b[1;32md:\\Users\\juanp_schamun\\Documents\\GitRepositories\\CEIA\\aprendizaje_profundo\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1659\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[0;32m   1660\u001b[0m         mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m-> 1661\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[0;32m   1662\u001b[0m     f,\n\u001b[0;32m   1663\u001b[0m     mode,\n\u001b[0;32m   1664\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1665\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1666\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[0;32m   1667\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[0;32m   1668\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   1669\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1670\u001b[0m )\n\u001b[0;32m   1671\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1672\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
            "File \u001b[1;32md:\\Users\\juanp_schamun\\Documents\\GitRepositories\\CEIA\\aprendizaje_profundo\\.venv\\Lib\\site-packages\\pandas\\io\\common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    854\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    855\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    856\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    857\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[0;32m    858\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[1;32m--> 859\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[0;32m    860\u001b[0m             handle,\n\u001b[0;32m    861\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[0;32m    862\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[0;32m    863\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m    864\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    865\u001b[0m         )\n\u001b[0;32m    866\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    867\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[0;32m    868\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
            "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/Trabajo AP/Material/class_7_wine_dataset_v2.csv'"
          ]
        }
      ],
      "source": [
        "# Carga del dataset\n",
        "df = pd.read_csv(\"..\\..\\clase_3\\data\\class_7_wine_dataset_v2.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hwnhhYwHk-yf"
      },
      "outputs": [],
      "source": [
        "# Type es tipo categ√≥rica, transformamos con One Hot Encoding\n",
        "type_dummies = pd.get_dummies(df['type'], prefix=\"type\")\n",
        "type_dummies\n",
        "df = pd.concat([df,type_dummies], axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oRo9kIhLo-44"
      },
      "outputs": [],
      "source": [
        "# Transformamos quality a quality label\n",
        "df[\"quality_label\"] = df[\"quality\"].apply(lambda q:0 if q<=6 else 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ddfgs8-oqdJh"
      },
      "outputs": [],
      "source": [
        "# Como tenemos pocos nan, borramos las filas donde hay nan y trabajamos con un dataset completo\n",
        "ds = df[df.isna().sum(axis = 1) == 0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "pXT51JETGdIF",
        "outputId": "2a79e417-e272-4de7-a6a4-b45c3b903b0c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Axes: >"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjAAAAGdCAYAAAAMm0nCAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAoCUlEQVR4nO3df3RUdX7/8VcSMhMCDBHcJKQEjHKUREEEKpn1xwIbkmJqdU3P6mqRKmhhg6dJTgGpyM91w1IRWQ3SFST0VIqwR+1KKMkYFigSRCNpEZSuCzbuwRmqLgzyYzJJ7vePPTNfht8TZ274hOfjHM7ZufczN595k5jnzmRIgmVZlgAAAAyS2NkbAAAAiBYBAwAAjEPAAAAA4xAwAADAOAQMAAAwDgEDAACMQ8AAAADjEDAAAMA43Tp7A/HS3t6uw4cPq1evXkpISOjs7QAAgMtgWZaOHz+urKwsJSZe+HmWLhswhw8fVnZ2dmdvAwAAdMAXX3yh/v37X/B8lw2YXr16SfrTAFwuV8yuGwwGVVdXp8LCQiUnJ8fsujgXs7YHc7YHc7YHc7ZHPOfs9/uVnZ0d/j5+IV02YEIvG7lcrpgHTGpqqlwuF18cccas7cGc7cGc7cGc7WHHnC/14x/8EC8AADAOAQMAAIxDwAAAAOMQMAAAwDgEDAAAMA4BAwAAjEPAAAAA4xAwAADAOAQMAAAwDgEDAACMQ8AAAADjEDAAAMA4BAwAADAOAQMAAIzTrbM3YKpb5tUq0HbxX/V9Jfl8UXFnbwEAgJjhGRgAAGAcAgYAABiHgAEAAMYhYAAAgHEIGAAAYBwCBgAAGIeAAQAAxiFgAACAcQgYAABgHAIGAAAYJ6qAmTdvnhISEiL+DB48OHz+9OnTKi0tVd++fdWzZ0+VlJTI5/NFXKO5uVnFxcVKTU1Venq6pk+frtbW1og1W7du1fDhw+V0OjVo0CBVV1d3/BECAIAuJ+pnYG6++WZ9+eWX4T87duwInysvL9c777yjDRs2aNu2bTp8+LAeeOCB8Pm2tjYVFxerpaVFO3fu1Jo1a1RdXa05c+aE1xw6dEjFxcUaM2aMmpqaVFZWpsmTJ6u2tvY7PlQAANBVRP3LHLt166bMzMxzjh87dkyrVq3S2rVrNXbsWEnS6tWrlZubq127dik/P191dXXav3+/3n33XWVkZGjYsGFauHChZs6cqXnz5snhcGjFihXKycnRkiVLJEm5ubnasWOHli5dqqKiou/4cAEAQFcQdcD87ne/U1ZWllJSUuR2u1VZWakBAwaosbFRwWBQBQUF4bWDBw/WgAED1NDQoPz8fDU0NGjIkCHKyMgIrykqKtLUqVO1b98+3XbbbWpoaIi4RmhNWVnZRfcVCAQUCATCt/1+vyQpGAwqGAxG+zAvKHQtZ6IVs2vaIZYzsEtozybu3STM2R7M2R7M2R7xnPPlXjOqgBk1apSqq6t100036csvv9T8+fN111136eOPP5bX65XD4VBaWlrEfTIyMuT1eiVJXq83Il5C50PnLrbG7/fr1KlT6t69+3n3VllZqfnz559zvK6uTqmpqdE8zMuycGR7zK8ZT5s2bersLXSYx+Pp7C1cFZizPZizPZizPeIx55MnT17WuqgCZvz48eH/PXToUI0aNUoDBw7U+vXrLxgWdpk1a5YqKirCt/1+v7Kzs1VYWCiXyxWzjxMMBuXxePTsh4kKtCfE7Lrx9vE8815+C8163LhxSk5O7uztdFnM2R7M2R7M2R7xnHPoFZRLifolpDOlpaXpxhtv1GeffaZx48appaVFR48ejXgWxufzhX9mJjMzU7t37464RuhdSmeuOfudSz6fTy6X66KR5HQ65XQ6zzmenJwcl0/iQHuCAm3mBIzJX8jx+jtEJOZsD+ZsD+Zsj3jM+XKv953+HZhvv/1Wv//979WvXz+NGDFCycnJqq+vD58/cOCAmpub5Xa7JUlut1t79+7VkSNHwms8Ho9cLpfy8vLCa868RmhN6BoAAABRBcw//MM/aNu2bfr888+1c+dO/ehHP1JSUpJ+8pOfqHfv3po0aZIqKir029/+Vo2NjXrsscfkdruVn58vSSosLFReXp4mTJig//qv/1Jtba1mz56t0tLS8LMnU6ZM0cGDBzVjxgx9+umnWr58udavX6/y8vLYP3oAAGCkqF5C+sMf/qCf/OQn+vrrr/W9731Pd955p3bt2qXvfe97kqSlS5cqMTFRJSUlCgQCKioq0vLly8P3T0pK0saNGzV16lS53W716NFDEydO1IIFC8JrcnJyVFNTo/Lyci1btkz9+/fXypUreQs1AAAIiypg1q1bd9HzKSkpqqqqUlVV1QXXDBw48JLviBk9erT27NkTzdYAAMBVhN+FBAAAjEPAAAAA4xAwAADAOAQMAAAwDgEDAACMQ8AAAADjEDAAAMA4BAwAADAOAQMAAIxDwAAAAOMQMAAAwDgEDAAAMA4BAwAAjEPAAAAA4xAwAADAOAQMAAAwDgEDAACMQ8AAAADjEDAAAMA4BAwAADAOAQMAAIxDwAAAAOMQMAAAwDgEDAAAMA4BAwAAjEPAAAAA4xAwAADAOAQMAAAwDgEDAACMQ8AAAADjEDAAAMA4BAwAADAOAQMAAIxDwAAAAOMQMAAAwDgEDAAAMA4BAwAAjEPAAAAA4xAwAADAOAQMAAAwDgEDAACMQ8AAAADjEDAAAMA4BAwAADAOAQMAAIxDwAAAAOMQMAAAwDgEDAAAMA4BAwAAjEPAAAAA4xAwAADAOAQMAAAwDgEDAACMQ8AAAADjEDAAAMA4BAwAADDOdwqYRYsWKSEhQWVlZeFjp0+fVmlpqfr27auePXuqpKREPp8v4n7Nzc0qLi5Wamqq0tPTNX36dLW2tkas2bp1q4YPHy6n06lBgwapurr6u2wVAAB0IR0OmA8++ED//M//rKFDh0YcLy8v1zvvvKMNGzZo27ZtOnz4sB544IHw+ba2NhUXF6ulpUU7d+7UmjVrVF1drTlz5oTXHDp0SMXFxRozZoyamppUVlamyZMnq7a2tqPbBQAAXUiHAubbb7/VI488oldffVXXXHNN+PixY8e0atUqvfDCCxo7dqxGjBih1atXa+fOndq1a5ckqa6uTvv379e//uu/atiwYRo/frwWLlyoqqoqtbS0SJJWrFihnJwcLVmyRLm5uZo2bZr++q//WkuXLo3BQwYAAKbrUMCUlpaquLhYBQUFEccbGxsVDAYjjg8ePFgDBgxQQ0ODJKmhoUFDhgxRRkZGeE1RUZH8fr/27dsXXnP2tYuKisLXAAAAV7du0d5h3bp1+uijj/TBBx+cc87r9crhcCgtLS3ieEZGhrxeb3jNmfESOh86d7E1fr9fp06dUvfu3c/52IFAQIFAIHzb7/dLkoLBoILBYJSP8sJC13ImWjG7ph1iOQO7hPZs4t5NwpztwZztwZztEc85X+41owqYL774Qn//938vj8ejlJSUDm0sXiorKzV//vxzjtfV1Sk1NTXmH2/hyPaYXzOeNm3a1Nlb6DCPx9PZW7gqMGd7MGd7MGd7xGPOJ0+evKx1UQVMY2Ojjhw5ouHDh4ePtbW1afv27Xr55ZdVW1urlpYWHT16NOJZGJ/Pp8zMTElSZmamdu/eHXHd0LuUzlxz9juXfD6fXC7XeZ99kaRZs2apoqIifNvv9ys7O1uFhYVyuVzRPMyLCgaD8ng8evbDRAXaE2J23Xj7eF5RZ28haqFZjxs3TsnJyZ29nS6LOduDOduDOdsjnnMOvYJyKVEFzA9/+EPt3bs34thjjz2mwYMHa+bMmcrOzlZycrLq6+tVUlIiSTpw4ICam5vldrslSW63W88995yOHDmi9PR0SX8qOJfLpby8vPCas58x8Hg84Wucj9PplNPpPOd4cnJyXD6JA+0JCrSZEzAmfyHH6+8QkZizPZizPZizPeIx58u9XlQB06tXL91yyy0Rx3r06KG+ffuGj0+aNEkVFRXq06ePXC6XnnrqKbndbuXn50uSCgsLlZeXpwkTJmjx4sXyer2aPXu2SktLwwEyZcoUvfzyy5oxY4Yef/xxbdmyRevXr1dNTU002wUAAF1U1D/EeylLly5VYmKiSkpKFAgEVFRUpOXLl4fPJyUlaePGjZo6darcbrd69OihiRMnasGCBeE1OTk5qqmpUXl5uZYtW6b+/ftr5cqVKioy72UQAAAQe985YLZu3RpxOyUlRVVVVaqqqrrgfQYOHHjJHyodPXq09uzZ8123BwAAuiB+FxIAADAOAQMAAIxDwAAAAOMQMAAAwDgEDAAAMA4BAwAAjEPAAAAA4xAwAADAOAQMAAAwDgEDAACMQ8AAAADjEDAAAMA4BAwAADAOAQMAAIxDwAAAAOMQMAAAwDgEDAAAMA4BAwAAjEPAAAAA4xAwAADAOAQMAAAwDgEDAACMQ8AAAADjEDAAAMA4BAwAADAOAQMAAIxDwAAAAOMQMAAAwDgEDAAAMA4BAwAAjEPAAAAA4xAwAADAOAQMAAAwDgEDAACMQ8AAAADjEDAAAMA4BAwAADAOAQMAAIxDwAAAAOMQMAAAwDgEDAAAMA4BAwAAjEPAAAAA4xAwAADAOAQMAAAwDgEDAACMQ8AAAADjEDAAAMA4BAwAADAOAQMAAIxDwAAAAOMQMAAAwDgEDAAAMA4BAwAAjEPAAAAA4xAwAADAOAQMAAAwTlQB88orr2jo0KFyuVxyuVxyu936j//4j/D506dPq7S0VH379lXPnj1VUlIin88XcY3m5mYVFxcrNTVV6enpmj59ulpbWyPWbN26VcOHD5fT6dSgQYNUXV3d8UcIAAC6nKgCpn///lq0aJEaGxv14YcfauzYsbrvvvu0b98+SVJ5ebneeecdbdiwQdu2bdPhw4f1wAMPhO/f1tam4uJitbS0aOfOnVqzZo2qq6s1Z86c8JpDhw6puLhYY8aMUVNTk8rKyjR58mTV1tbG6CEDAADTdYtm8b333htx+7nnntMrr7yiXbt2qX///lq1apXWrl2rsWPHSpJWr16t3Nxc7dq1S/n5+aqrq9P+/fv17rvvKiMjQ8OGDdPChQs1c+ZMzZs3Tw6HQytWrFBOTo6WLFkiScrNzdWOHTu0dOlSFRUVxehhAwAAk0UVMGdqa2vThg0bdOLECbndbjU2NioYDKqgoCC8ZvDgwRowYIAaGhqUn5+vhoYGDRkyRBkZGeE1RUVFmjp1qvbt26fbbrtNDQ0NEdcIrSkrK7vofgKBgAKBQPi23++XJAWDQQWDwY4+zHOEruVMtGJ2TTvEcgZ2Ce3ZxL2bhDnbgznbgznbI55zvtxrRh0we/fuldvt1unTp9WzZ0+99dZbysvLU1NTkxwOh9LS0iLWZ2RkyOv1SpK8Xm9EvITOh85dbI3f79epU6fUvXv38+6rsrJS8+fPP+d4XV2dUlNTo32Yl7RwZHvMrxlPmzZt6uwtdJjH4+nsLVwVmLM9mLM9mLM94jHnkydPXta6qAPmpptuUlNTk44dO6Zf//rXmjhxorZt2xb1BmNt1qxZqqioCN/2+/3Kzs5WYWGhXC5XzD5OMBiUx+PRsx8mKtCeELPrxtvH88x7+S0063Hjxik5Obmzt9NlMWd7MGd7MGd7xHPOoVdQLiXqgHE4HBo0aJAkacSIEfrggw+0bNkyPfjgg2ppadHRo0cjnoXx+XzKzMyUJGVmZmr37t0R1wu9S+nMNWe/c8nn88nlcl3w2RdJcjqdcjqd5xxPTk6OyydxoD1BgTZzAsbkL+R4/R0iEnO2B3O2B3O2RzzmfLnX+87/Dkx7e7sCgYBGjBih5ORk1dfXh88dOHBAzc3NcrvdkiS32629e/fqyJEj4TUej0cul0t5eXnhNWdeI7QmdA0AAIConoGZNWuWxo8frwEDBuj48eNau3attm7dqtraWvXu3VuTJk1SRUWF+vTpI5fLpaeeekput1v5+fmSpMLCQuXl5WnChAlavHixvF6vZs+erdLS0vCzJ1OmTNHLL7+sGTNm6PHHH9eWLVu0fv161dTUxP7RAwAAI0UVMEeOHNGjjz6qL7/8Ur1799bQoUNVW1urcePGSZKWLl2qxMRElZSUKBAIqKioSMuXLw/fPykpSRs3btTUqVPldrvVo0cPTZw4UQsWLAivycnJUU1NjcrLy7Vs2TL1799fK1eu5C3UAAAgLKqAWbVq1UXPp6SkqKqqSlVVVRdcM3DgwEu+I2b06NHas2dPNFsDAABXEX4XEgAAMA4BAwAAjEPAAAAA4xAwAADAOAQMAAAwDgEDAACMQ8AAAADjEDAAAMA4BAwAADAOAQMAAIxDwAAAAOMQMAAAwDgEDAAAMA4BAwAAjEPAAAAA4xAwAADAOAQMAAAwDgEDAACMQ8AAAADjEDAAAMA4BAwAADAOAQMAAIxDwAAAAOMQMAAAwDgEDAAAMA4BAwAAjEPAAAAA4xAwAADAOAQMAAAwDgEDAACMQ8AAAADjEDAAAMA4BAwAADAOAQMAAIxDwAAAAOMQMAAAwDgEDAAAMA4BAwAAjEPAAAAA4xAwAADAOAQMAAAwDgEDAACMQ8AAAADjEDAAAMA4BAwAADAOAQMAAIxDwAAAAOMQMAAAwDgEDAAAMA4BAwAAjEPAAAAA4xAwAADAOAQMAAAwDgEDAACMQ8AAAADjEDAAAMA4UQVMZWWl/vzP/1y9evVSenq67r//fh04cCBizenTp1VaWqq+ffuqZ8+eKikpkc/ni1jT3Nys4uJipaamKj09XdOnT1dra2vEmq1bt2r48OFyOp0aNGiQqqurO/YIAQBAlxNVwGzbtk2lpaXatWuXPB6PgsGgCgsLdeLEifCa8vJyvfPOO9qwYYO2bdumw4cP64EHHgifb2trU3FxsVpaWrRz506tWbNG1dXVmjNnTnjNoUOHVFxcrDFjxqipqUllZWWaPHmyamtrY/CQAQCA6bpFs3jz5s0Rt6urq5Wenq7GxkbdfffdOnbsmFatWqW1a9dq7NixkqTVq1crNzdXu3btUn5+vurq6rR//369++67ysjI0LBhw7Rw4ULNnDlT8+bNk8Ph0IoVK5STk6MlS5ZIknJzc7Vjxw4tXbpURUVFMXroAADAVFEFzNmOHTsmSerTp48kqbGxUcFgUAUFBeE1gwcP1oABA9TQ0KD8/Hw1NDRoyJAhysjICK8pKirS1KlTtW/fPt12221qaGiIuEZoTVlZ2QX3EggEFAgEwrf9fr8kKRgMKhgMfpeHGSF0LWeiFbNr2iGWM7BLaM8m7t0kzNkezNkezNke8Zzz5V6zwwHT3t6usrIy3XHHHbrlllskSV6vVw6HQ2lpaRFrMzIy5PV6w2vOjJfQ+dC5i63x+/06deqUunfvfs5+KisrNX/+/HOO19XVKTU1tWMP8iIWjmyP+TXjadOmTZ29hQ7zeDydvYWrAnO2B3O2B3O2RzzmfPLkycta1+GAKS0t1ccff6wdO3Z09BIxNWvWLFVUVIRv+/1+ZWdnq7CwUC6XK2YfJxgMyuPx6NkPExVoT4jZdePt43nmvfQWmvW4ceOUnJzc2dvpspizPZizPZizPeI559ArKJfSoYCZNm2aNm7cqO3bt6t///7h45mZmWppadHRo0cjnoXx+XzKzMwMr9m9e3fE9ULvUjpzzdnvXPL5fHK5XOd99kWSnE6nnE7nOceTk5Pj8kkcaE9QoM2cgDH5Czlef4eIxJztwZztwZztEY85X+71onoXkmVZmjZtmt566y1t2bJFOTk5EedHjBih5ORk1dfXh48dOHBAzc3NcrvdkiS32629e/fqyJEj4TUej0cul0t5eXnhNWdeI7QmdA0AAHB1i+oZmNLSUq1du1b//u//rl69eoV/ZqV3797q3r27evfurUmTJqmiokJ9+vSRy+XSU089Jbfbrfz8fElSYWGh8vLyNGHCBC1evFher1ezZ89WaWlp+BmUKVOm6OWXX9aMGTP0+OOPa8uWLVq/fr1qampi/PABAICJonoG5pVXXtGxY8c0evRo9evXL/znjTfeCK9ZunSp/vIv/1IlJSW6++67lZmZqTfffDN8PikpSRs3blRSUpLcbrf+5m/+Ro8++qgWLFgQXpOTk6Oamhp5PB7deuutWrJkiVauXMlbqAEAgKQon4GxrEu/dTglJUVVVVWqqqq64JqBAwde8l0xo0eP1p49e6LZHgAAuErwu5AAAIBxCBgAAGAcAgYAABiHgAEAAMYhYAAAgHEIGAAAYBwCBgAAGIeAAQAAxiFgAACAcQgYAABgHAIGAAAYh4ABAADGIWAAAIBxCBgAAGAcAgYAABiHgAEAAMYhYAAAgHEIGAAAYBwCBgAAGIeAAQAAxiFgAACAcQgYAABgHAIGAAAYh4ABAADGIWAAAIBxCBgAAGAcAgYAABiHgAEAAMYhYAAAgHEIGAAAYBwCBgAAGIeAAQAAxiFgAACAcQgYAABgHAIGAAAYh4ABAADGIWAAAIBxCBgAAGAcAgYAABiHgAEAAMYhYAAAgHEIGAAAYJxunb0BAACudtc9XdPZW4iKM8nS4ts7dw88AwMAAIxDwAAAAOMQMAAAwDgEDAAAMA4BAwAAjEPAAAAA4xAwAADAOAQMAAAwDgEDAACMQ8AAAADjEDAAAMA4BAwAADAOAQMAAIxDwAAAAONEHTDbt2/Xvffeq6ysLCUkJOjtt9+OOG9ZlubMmaN+/fqpe/fuKigo0O9+97uINd98840eeeQRuVwupaWladKkSfr2228j1vz3f/+37rrrLqWkpCg7O1uLFy+O/tEBAIAuKeqAOXHihG699VZVVVWd9/zixYv1y1/+UitWrND777+vHj16qKioSKdPnw6veeSRR7Rv3z55PB5t3LhR27dv15NPPhk+7/f7VVhYqIEDB6qxsVH/9E//pHnz5ulXv/pVBx4iAADoarpFe4fx48dr/Pjx5z1nWZZefPFFzZ49W/fdd58k6V/+5V+UkZGht99+Ww899JA++eQTbd68WR988IFGjhwpSXrppZd0zz336Pnnn1dWVpZef/11tbS06LXXXpPD4dDNN9+spqYmvfDCCxGhAwAArk5RB8zFHDp0SF6vVwUFBeFjvXv31qhRo9TQ0KCHHnpIDQ0NSktLC8eLJBUUFCgxMVHvv/++fvSjH6mhoUF33323HA5HeE1RUZF+8Ytf6I9//KOuueaacz52IBBQIBAI3/b7/ZKkYDCoYDAYs8cYupYz0YrZNe0QyxnYJbRnE/duEuZsD+ZsD1Pn7Ewy63tK6HtgPOZ8udeMacB4vV5JUkZGRsTxjIyM8Dmv16v09PTITXTrpj59+kSsycnJOecaoXPnC5jKykrNnz//nON1dXVKTU3t4CO6sIUj22N+zXjatGlTZ2+hwzweT2dv4arAnO3BnO1h2pwX397ZO+iYeMz55MmTl7UupgHTmWbNmqWKiorwbb/fr+zsbBUWFsrlcsXs4wSDQXk8Hj37YaIC7Qkxu268fTyvqLO3ELXQrMeNG6fk5OTO3k6XxZztwZztYeqcb5lX29lbiIoz0dLCke1xmXPoFZRLiWnAZGZmSpJ8Pp/69esXPu7z+TRs2LDwmiNHjkTcr7W1Vd988034/pmZmfL5fBFrQrdDa87mdDrldDrPOZ6cnByXT+JAe4ICbeYEjElfyGeL198hIjFnezBne5g2Z5O+n5wpHnO+3OvF9N+BycnJUWZmpurr68PH/H6/3n//fbndbkmS2+3W0aNH1djYGF6zZcsWtbe3a9SoUeE127dvj3gdzOPx6Kabbjrvy0cAAODqEnXAfPvtt2pqalJTU5OkP/3gblNTk5qbm5WQkKCysjL97Gc/029+8xvt3btXjz76qLKysnT//fdLknJzc/UXf/EXeuKJJ7R792699957mjZtmh566CFlZWVJkh5++GE5HA5NmjRJ+/bt0xtvvKFly5ZFvEQEAACuXlG/hPThhx9qzJgx4duhqJg4caKqq6s1Y8YMnThxQk8++aSOHj2qO++8U5s3b1ZKSkr4Pq+//rqmTZumH/7wh0pMTFRJSYl++ctfhs/37t1bdXV1Ki0t1YgRI3Tttddqzpw5vIUaAABI6kDAjB49WpZ14bd7JSQkaMGCBVqwYMEF1/Tp00dr16696McZOnSo/vM//zPa7QEAgKsAvwsJAAAYh4ABAADGIWAAAIBxCBgAAGAcAgYAABiHgAEAAMYhYAAAgHEIGAAAYBwCBgAAGIeAAQAAxiFgAACAcQgYAABgHAIGAAAYh4ABAADGIWAAAIBxCBgAAGAcAgYAABiHgAEAAMYhYAAAgHEIGAAAYBwCBgAAGIeAAQAAxiFgAACAcQgYAABgHAIGAAAYh4ABAADGIWAAAIBxCBgAAGAcAgYAABiHgAEAAMYhYAAAgHEIGAAAYBwCBgAAGIeAAQAAxiFgAACAcQgYAABgHAIGAAAYh4ABAADGIWAAAIBxCBgAAGAcAgYAABiHgAEAAMYhYAAAgHEIGAAAYBwCBgAAGIeAAQAAxiFgAACAcQgYAABgHAIGAAAYh4ABAADGIWAAAIBxCBgAAGAcAgYAABiHgAEAAMYhYAAAgHEIGAAAYJwrOmCqqqp03XXXKSUlRaNGjdLu3bs7e0sAAOAKcMUGzBtvvKGKigrNnTtXH330kW699VYVFRXpyJEjnb01AADQya7YgHnhhRf0xBNP6LHHHlNeXp5WrFih1NRUvfbaa529NQAA0Mm6dfYGzqelpUWNjY2aNWtW+FhiYqIKCgrU0NBw3vsEAgEFAoHw7WPHjkmSvvnmGwWDwZjtLRgM6uTJk+oWTFRbe0LMrhtvX3/9dWdvIWqhWX/99ddKTk7u7O10WczZHszZHqbOuVvric7eQlS6tVs6ebI9LnM+fvy4JMmyrIvvIaYfNUa++uortbW1KSMjI+J4RkaGPv300/Pep7KyUvPnzz/neE5OTlz2aJprl3T2DgAAXcnDcb7+8ePH1bt37wuevyIDpiNmzZqlioqK8O329nZ988036tu3rxISYvdMid/vV3Z2tr744gu5XK6YXRfnYtb2YM72YM72YM72iOecLcvS8ePHlZWVddF1V2TAXHvttUpKSpLP54s47vP5lJmZed77OJ1OOZ3OiGNpaWnx2qJcLhdfHDZh1vZgzvZgzvZgzvaI15wv9sxLyBX5Q7wOh0MjRoxQfX19+Fh7e7vq6+vldrs7cWcAAOBKcEU+AyNJFRUVmjhxokaOHKnbb79dL774ok6cOKHHHnuss7cGAAA62RUbMA8++KD+7//+T3PmzJHX69WwYcO0efPmc36w125Op1Nz58495+UqxB6ztgdztgdztgdztseVMOcE61LvUwIAALjCXJE/AwMAAHAxBAwAADAOAQMAAIxDwAAAAOMQMOdRVVWl6667TikpKRo1apR279590fUbNmzQ4MGDlZKSoiFDhmjTpk027dR80cz61Vdf1V133aVrrrlG11xzjQoKCi75d4M/ifZzOmTdunVKSEjQ/fffH98NdhHRzvno0aMqLS1Vv3795HQ6deONN/Lfj8sQ7ZxffPFF3XTTTerevbuys7NVXl6u06dP27RbM23fvl333nuvsrKylJCQoLfffvuS99m6dauGDx8up9OpQYMGqbq6Or6btBBh3bp1lsPhsF577TVr37591hNPPGGlpaVZPp/vvOvfe+89KykpyVq8eLG1f/9+a/bs2VZycrK1d+9em3dunmhn/fDDD1tVVVXWnj17rE8++cT627/9W6t3797WH/7wB5t3bpZo5xxy6NAh68/+7M+su+66y7rvvvvs2azBop1zIBCwRo4cad1zzz3Wjh07rEOHDllbt261mpqabN65WaKd8+uvv245nU7r9ddftw4dOmTV1tZa/fr1s8rLy23euVk2bdpkPfPMM9abb75pSbLeeuuti64/ePCglZqaalVUVFj79++3XnrpJSspKcnavHlz3PZIwJzl9ttvt0pLS8O329rarKysLKuysvK863/84x9bxcXFEcdGjRpl/d3f/V1c99kVRDvrs7W2tlq9evWy1qxZE68tdgkdmXNra6v1/e9/31q5cqU1ceJEAuYyRDvnV155xbr++uutlpYWu7bYJUQ759LSUmvs2LERxyoqKqw77rgjrvvsSi4nYGbMmGHdfPPNEccefPBBq6ioKG774iWkM7S0tKixsVEFBQXhY4mJiSooKFBDQ8N579PQ0BCxXpKKioouuB5/0pFZn+3kyZMKBoPq06dPvLZpvI7OecGCBUpPT9ekSZPs2KbxOjLn3/zmN3K73SotLVVGRoZuueUW/fznP1dbW5td2zZOR+b8/e9/X42NjeGXmQ4ePKhNmzbpnnvusWXPV4vO+F54xf5LvJ3hq6++Ultb2zn/2m9GRoY+/fTT897H6/Wed73X643bPruCjsz6bDNnzlRWVtY5XzT4/zoy5x07dmjVqlVqamqyYYddQ0fmfPDgQW3ZskWPPPKINm3apM8++0w//elPFQwGNXfuXDu2bZyOzPnhhx/WV199pTvvvFOWZam1tVVTpkzRP/7jP9qx5avGhb4X+v1+nTp1St27d4/5x+QZGBhp0aJFWrdund566y2lpKR09na6jOPHj2vChAl69dVXde2113b2drq09vZ2paen61e/+pVGjBihBx98UM8884xWrFjR2VvrUrZu3aqf//znWr58uT766CO9+eabqqmp0cKFCzt7a/iOeAbmDNdee62SkpLk8/kijvt8PmVmZp73PpmZmVGtx590ZNYhzz//vBYtWqR3331XQ4cOjec2jRftnH//+9/r888/17333hs+1t7eLknq1q2bDhw4oBtuuCG+mzZQRz6f+/Xrp+TkZCUlJYWP5ebmyuv1qqWlRQ6HI657NlFH5vzss89qwoQJmjx5siRpyJAhOnHihJ588kk988wzSkzk/8fHwoW+F7pcrrg8+yLxDEwEh8OhESNGqL6+Pnysvb1d9fX1crvd572P2+2OWC9JHo/nguvxJx2ZtSQtXrxYCxcu1ObNmzVy5Eg7tmq0aOc8ePBg7d27V01NTeE/f/VXf6UxY8aoqalJ2dnZdm7fGB35fL7jjjv02WefhQNRkv7nf/5H/fr1I14uoCNzPnny5DmREopGi18FGDOd8r0wbj8ebKh169ZZTqfTqq6utvbv3289+eSTVlpamuX1ei3LsqwJEyZYTz/9dHj9e++9Z3Xr1s16/vnnrU8++cSaO3cub6O+TNHOetGiRZbD4bB+/etfW19++WX4z/HjxzvrIRgh2jmfjXchXZ5o59zc3Gz16tXLmjZtmnXgwAFr48aNVnp6uvWzn/2ssx6CEaKd89y5c61evXpZ//Zv/2YdPHjQqqurs2644Qbrxz/+cWc9BCMcP37c2rNnj7Vnzx5LkvXCCy9Ye/bssf73f//XsizLevrpp60JEyaE14feRj19+nTrk08+saqqqngbdWd46aWXrAEDBlgOh8O6/fbbrV27doXP/eAHP7AmTpwYsX79+vXWjTfeaDkcDuvmm2+2ampqbN6xuaKZ9cCBAy1J5/yZO3eu/Rs3TLSf02ciYC5ftHPeuXOnNWrUKMvpdFrXX3+99dxzz1mtra0279o80cw5GAxa8+bNs2644QYrJSXFys7Otn76059af/zjH+3fuEF++9vfnve/t6HZTpw40frBD35wzn2GDRtmORwO6/rrr7dWr14d1z0mWBbPoQEAALPwMzAAAMA4BAwAADAOAQMAAIxDwAAAAOMQMAAAwDgEDAAAMA4BAwAAjEPAAAAA4xAwAADAOAQMAAAwDgEDAACMQ8AAAADj/D/HLaLzfHp7SAAAAABJRU5ErkJggg==",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# El dataset est√° desbalanceado hacia los vinos \"malos\"\n",
        "df[\"quality_label\"].hist()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TmBJD3siinlF"
      },
      "source": [
        "## Armado del dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zE5f2XsqrTr_"
      },
      "outputs": [],
      "source": [
        "# Recordar que debo borrar del dataset de entrada mi columna de salida!\n",
        "x = ds.drop(['Unnamed: 0','type','vendor_id','quality','quality_label'], axis=1) \n",
        "y = ds['quality_label']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oNDPgGUNsvR8"
      },
      "source": [
        "## Normalizacion\n",
        "\n",
        "Las redes neuronales no requieren que los datos esten normalizados, pero la normalizaci√≥n ayuda a que el algoritmo de gradient descent converga m√°s r√°pido."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N6MXPnges8HE"
      },
      "outputs": [],
      "source": [
        "# Convierto a numpy\n",
        "x = x.to_numpy()\n",
        "y = y.to_numpy()\n",
        "# Normalizaci√≥n min max\n",
        "x_norm = (x - np.min(x, axis=0)) / (np.max(x, axis=0 ) - np.min(x, axis=0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1VVapvoTjvCm"
      },
      "source": [
        "## Divisi√≥n del dataset\n",
        "Divido en entrenamiento y validaci√≥n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C9dDhJqfyjkE"
      },
      "outputs": [],
      "source": [
        "idx = np.random.permutation(x_norm.shape[0])\n",
        "train_idx = idx[0:int(0.85*len(idx))]\n",
        "valid_idx = idx[int(0.85*len(idx)):]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-VbD8cR8yzD4"
      },
      "outputs": [],
      "source": [
        "train_x = x_norm[train_idx]\n",
        "train_y = y[train_idx]\n",
        "valid_x = x_norm[valid_idx]\n",
        "valid_y = y[valid_idx]\n",
        "\n",
        "n_train = train_x.shape[0]\n",
        "n_valid = valid_x.shape[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bTEFahXrwte2"
      },
      "source": [
        "## Pytorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sCQz7nDkuK7S"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn import metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ducia7gqEBJz",
        "outputId": "82fa92ea-21b1-4cf3-90bc-dd15ebe31814"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'cpu'"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device = \"cpu\"\n",
        "if torch.cuda.is_available():\n",
        "  device = \"cuda:0\"\n",
        "\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "gUpc_S5Fw_Nk"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'Dataset' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32md:\\Users\\juanp_schamun\\Documents\\GitRepositories\\CEIA\\aprendizaje_profundo\\clase_3\\jupyter_notebooks\\Clase3_Pytorch_Custom_Loss.ipynb Cell 19\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Users/juanp_schamun/Documents/GitRepositories/CEIA/aprendizaje_profundo/clase_3/jupyter_notebooks/Clase3_Pytorch_Custom_Loss.ipynb#X24sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Pytorch necesita de una clase de dataset que extienda de torch.utils.data.Dataset\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Users/juanp_schamun/Documents/GitRepositories/CEIA/aprendizaje_profundo/clase_3/jupyter_notebooks/Clase3_Pytorch_Custom_Loss.ipynb#X24sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m# Esta clase dataset debe sobreescribir los m√©todos init, len y getitem\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Users/juanp_schamun/Documents/GitRepositories/CEIA/aprendizaje_profundo/clase_3/jupyter_notebooks/Clase3_Pytorch_Custom_Loss.ipynb#X24sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mMyDataset\u001b[39;00m(Dataset):\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Users/juanp_schamun/Documents/GitRepositories/CEIA/aprendizaje_profundo/clase_3/jupyter_notebooks/Clase3_Pytorch_Custom_Loss.ipynb#X24sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Users/juanp_schamun/Documents/GitRepositories/CEIA/aprendizaje_profundo/clase_3/jupyter_notebooks/Clase3_Pytorch_Custom_Loss.ipynb#X24sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m   \u001b[39m#__init__ guarda el dataset en una variable de clase\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Users/juanp_schamun/Documents/GitRepositories/CEIA/aprendizaje_profundo/clase_3/jupyter_notebooks/Clase3_Pytorch_Custom_Loss.ipynb#X24sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m   \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, x, y):\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Users/juanp_schamun/Documents/GitRepositories/CEIA/aprendizaje_profundo/clase_3/jupyter_notebooks/Clase3_Pytorch_Custom_Loss.ipynb#X24sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mx \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mfrom_numpy(x\u001b[39m.\u001b[39mastype(\u001b[39m'\u001b[39m\u001b[39mfloat\u001b[39m\u001b[39m'\u001b[39m))  \u001b[39m## Modif JP\u001b[39;00m\n",
            "\u001b[1;31mNameError\u001b[0m: name 'Dataset' is not defined"
          ]
        }
      ],
      "source": [
        "# Pytorch necesita de una clase de dataset que extienda de torch.utils.data.Dataset\n",
        "# Esta clase dataset debe sobreescribir los m√©todos init, len y getitem\n",
        "class MyDataset(Dataset):\n",
        "\n",
        "  #__init__ guarda el dataset en una variable de clase\n",
        "  def __init__(self, x, y):\n",
        "    self.x = torch.from_numpy(x.astype('float'))  ## Modif JP\n",
        "    self.y = torch.from_numpy(y.astype('float'))  ## Modif JP\n",
        "\n",
        "  # __len__ define el comportamiento de la funci√≥n len() sobre el objeto\n",
        "  def __len__(self):\n",
        "    return self.x.shape[0]\n",
        "\n",
        "  # __getitem__ define el comportamiento de los []\n",
        "  def __getitem__(self, idx):\n",
        "    return self.x[idx], self.y[idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eGbN4tbtzU6o"
      },
      "outputs": [],
      "source": [
        "# Creo el dataset de entrenamiento\n",
        "train_ds = MyDataset(train_x, train_y)\n",
        "# Creo el dataset de validaci√≥n\n",
        "valid_ds = MyDataset(valid_x, valid_y)\n",
        "\n",
        "# Pytorch utiliza DataLoader para entregar los dataset de a batches\n",
        "train_dataloader = DataLoader(train_ds, batch_size = 64, shuffle= True)\n",
        "valid_dataloader = DataLoader(valid_ds, batch_size=64)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GoKS1cfjn-oF"
      },
      "source": [
        "#### Entrenamiento con loss est√°ndar (BinaryCrossEntropy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1B95zN1m5r6c"
      },
      "outputs": [],
      "source": [
        "# Arquitectura red neuronal\n",
        "class NNet(torch.nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    # Defino la arquitectura de la red\n",
        "    super().__init__()\n",
        "    self.linear_1 = torch.nn.Linear(in_features=13, out_features=200, bias=True)\n",
        "    self.relu_1 = torch.nn.ReLU()\n",
        "    self.linear_2 = torch.nn.Linear(in_features = 200, out_features=100, bias=True)\n",
        "    self.relu_2 = torch.nn.ReLU()\n",
        "    self.linear_3 = torch.nn.Linear(in_features = 100, out_features= 1, bias=True)\n",
        "    self.output = torch.nn.Sigmoid()\n",
        "\n",
        "  def forward(self, x):\n",
        "    # Defino el c√°lculo del paso forward\n",
        "    x = self.linear_1(x)\n",
        "    x = self.relu_1(x)\n",
        "    x = self.linear_2(x)\n",
        "    x = self.relu_2(x)\n",
        "    x = self.linear_3(x)\n",
        "    x = self.output(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QLOh2lz4_NXl"
      },
      "outputs": [],
      "source": [
        "# Instanciamos la red\n",
        "nnet = NNet()\n",
        "# Copio la red neuronal al dispositivo donde entrene la red neuronal\n",
        "nnet = nnet.to(device)\n",
        "# Loss\n",
        "loss_function = torch.nn.BCELoss(reduction='sum')\n",
        "# Optimizer\n",
        "optimizer = torch.optim.Adam(nnet.parameters(), lr=0.0001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L9UeuiOmErqk",
        "outputId": "e9dfac0f-1248-473a-ab56-fe2861a9488c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Epoch 0 | Train/Valid loss: 0.650 / 0.594 | Train/Valid accuracy: 0.703 / 0.787 | Train/Valid recall: 0.147 / 0.000 | \n",
            " Epoch 1 | Train/Valid loss: 0.538 / 0.522 | Train/Valid accuracy: 0.806 / 0.787 | Train/Valid recall: 0.000 / 0.000 | \n",
            " Epoch 2 | Train/Valid loss: 0.491 / 0.509 | Train/Valid accuracy: 0.806 / 0.787 | Train/Valid recall: 0.000 / 0.000 | \n",
            " Epoch 3 | Train/Valid loss: 0.479 / 0.501 | Train/Valid accuracy: 0.806 / 0.787 | Train/Valid recall: 0.000 / 0.000 | \n",
            " Epoch 4 | Train/Valid loss: 0.469 / 0.490 | Train/Valid accuracy: 0.806 / 0.787 | Train/Valid recall: 0.000 / 0.000 | \n",
            " Epoch 5 | Train/Valid loss: 0.460 / 0.481 | Train/Valid accuracy: 0.806 / 0.787 | Train/Valid recall: 0.000 / 0.000 | \n",
            " Epoch 6 | Train/Valid loss: 0.450 / 0.470 | Train/Valid accuracy: 0.806 / 0.787 | Train/Valid recall: 0.000 / 0.000 | \n",
            " Epoch 7 | Train/Valid loss: 0.440 / 0.460 | Train/Valid accuracy: 0.806 / 0.787 | Train/Valid recall: 0.000 / 0.000 | \n",
            " Epoch 8 | Train/Valid loss: 0.431 / 0.450 | Train/Valid accuracy: 0.806 / 0.788 | Train/Valid recall: 0.000 / 0.005 | \n",
            " Epoch 9 | Train/Valid loss: 0.424 / 0.444 | Train/Valid accuracy: 0.808 / 0.791 | Train/Valid recall: 0.012 / 0.019 | \n",
            " Epoch 10 | Train/Valid loss: 0.418 / 0.439 | Train/Valid accuracy: 0.810 / 0.797 | Train/Valid recall: 0.030 / 0.048 | \n",
            " Epoch 11 | Train/Valid loss: 0.413 / 0.433 | Train/Valid accuracy: 0.812 / 0.799 | Train/Valid recall: 0.061 / 0.101 | \n",
            " Epoch 12 | Train/Valid loss: 0.409 / 0.430 | Train/Valid accuracy: 0.813 / 0.802 | Train/Valid recall: 0.096 / 0.121 | \n",
            " Epoch 13 | Train/Valid loss: 0.406 / 0.428 | Train/Valid accuracy: 0.816 / 0.802 | Train/Valid recall: 0.141 / 0.121 | \n",
            " Epoch 14 | Train/Valid loss: 0.403 / 0.424 | Train/Valid accuracy: 0.817 / 0.803 | Train/Valid recall: 0.164 / 0.150 | \n",
            " Epoch 15 | Train/Valid loss: 0.402 / 0.422 | Train/Valid accuracy: 0.819 / 0.805 | Train/Valid recall: 0.179 / 0.164 | \n",
            " Epoch 16 | Train/Valid loss: 0.400 / 0.421 | Train/Valid accuracy: 0.818 / 0.804 | Train/Valid recall: 0.195 / 0.155 | \n",
            " Epoch 17 | Train/Valid loss: 0.398 / 0.420 | Train/Valid accuracy: 0.819 / 0.805 | Train/Valid recall: 0.219 / 0.164 | \n",
            " Epoch 18 | Train/Valid loss: 0.397 / 0.417 | Train/Valid accuracy: 0.818 / 0.812 | Train/Valid recall: 0.206 / 0.203 | \n",
            " Epoch 19 | Train/Valid loss: 0.396 / 0.417 | Train/Valid accuracy: 0.819 / 0.811 | Train/Valid recall: 0.233 / 0.193 | \n",
            " Epoch 20 | Train/Valid loss: 0.394 / 0.414 | Train/Valid accuracy: 0.823 / 0.813 | Train/Valid recall: 0.237 / 0.227 | \n",
            " Epoch 21 | Train/Valid loss: 0.394 / 0.413 | Train/Valid accuracy: 0.822 / 0.810 | Train/Valid recall: 0.256 / 0.227 | \n",
            " Epoch 22 | Train/Valid loss: 0.392 / 0.413 | Train/Valid accuracy: 0.823 / 0.808 | Train/Valid recall: 0.255 / 0.208 | \n",
            " Epoch 23 | Train/Valid loss: 0.392 / 0.412 | Train/Valid accuracy: 0.824 / 0.808 | Train/Valid recall: 0.258 / 0.203 | \n",
            " Epoch 24 | Train/Valid loss: 0.390 / 0.413 | Train/Valid accuracy: 0.825 / 0.812 | Train/Valid recall: 0.267 / 0.198 | \n",
            " Epoch 25 | Train/Valid loss: 0.390 / 0.410 | Train/Valid accuracy: 0.825 / 0.810 | Train/Valid recall: 0.253 / 0.217 | \n",
            " Epoch 26 | Train/Valid loss: 0.389 / 0.410 | Train/Valid accuracy: 0.825 / 0.807 | Train/Valid recall: 0.271 / 0.203 | \n",
            " Epoch 27 | Train/Valid loss: 0.389 / 0.408 | Train/Valid accuracy: 0.824 / 0.807 | Train/Valid recall: 0.260 / 0.242 | \n",
            " Epoch 28 | Train/Valid loss: 0.388 / 0.407 | Train/Valid accuracy: 0.825 / 0.805 | Train/Valid recall: 0.271 / 0.237 | \n",
            " Epoch 29 | Train/Valid loss: 0.387 / 0.407 | Train/Valid accuracy: 0.825 / 0.812 | Train/Valid recall: 0.277 / 0.227 | \n",
            " Epoch 30 | Train/Valid loss: 0.387 / 0.407 | Train/Valid accuracy: 0.826 / 0.812 | Train/Valid recall: 0.263 / 0.227 | \n",
            " Epoch 31 | Train/Valid loss: 0.386 / 0.405 | Train/Valid accuracy: 0.824 / 0.805 | Train/Valid recall: 0.271 / 0.251 | \n",
            " Epoch 32 | Train/Valid loss: 0.386 / 0.406 | Train/Valid accuracy: 0.827 / 0.809 | Train/Valid recall: 0.284 / 0.232 | \n",
            " Epoch 33 | Train/Valid loss: 0.385 / 0.407 | Train/Valid accuracy: 0.827 / 0.809 | Train/Valid recall: 0.289 / 0.222 | \n",
            " Epoch 34 | Train/Valid loss: 0.385 / 0.406 | Train/Valid accuracy: 0.825 / 0.809 | Train/Valid recall: 0.274 / 0.222 | \n",
            " Epoch 35 | Train/Valid loss: 0.384 / 0.403 | Train/Valid accuracy: 0.827 / 0.803 | Train/Valid recall: 0.278 / 0.251 | \n",
            " Epoch 36 | Train/Valid loss: 0.384 / 0.404 | Train/Valid accuracy: 0.827 / 0.809 | Train/Valid recall: 0.292 / 0.237 | \n",
            " Epoch 37 | Train/Valid loss: 0.383 / 0.402 | Train/Valid accuracy: 0.828 / 0.806 | Train/Valid recall: 0.274 / 0.275 | \n",
            " Epoch 38 | Train/Valid loss: 0.383 / 0.403 | Train/Valid accuracy: 0.827 / 0.808 | Train/Valid recall: 0.287 / 0.246 | \n",
            " Epoch 39 | Train/Valid loss: 0.383 / 0.404 | Train/Valid accuracy: 0.827 / 0.810 | Train/Valid recall: 0.295 / 0.232 | \n",
            " Epoch 40 | Train/Valid loss: 0.383 / 0.403 | Train/Valid accuracy: 0.828 / 0.811 | Train/Valid recall: 0.290 / 0.246 | \n",
            " Epoch 41 | Train/Valid loss: 0.382 / 0.407 | Train/Valid accuracy: 0.825 / 0.810 | Train/Valid recall: 0.292 / 0.213 | \n",
            " Epoch 42 | Train/Valid loss: 0.382 / 0.403 | Train/Valid accuracy: 0.827 / 0.812 | Train/Valid recall: 0.285 / 0.246 | \n",
            " Epoch 43 | Train/Valid loss: 0.381 / 0.402 | Train/Valid accuracy: 0.827 / 0.811 | Train/Valid recall: 0.296 / 0.251 | \n",
            " Epoch 44 | Train/Valid loss: 0.381 / 0.400 | Train/Valid accuracy: 0.827 / 0.806 | Train/Valid recall: 0.288 / 0.261 | \n",
            " Epoch 45 | Train/Valid loss: 0.381 / 0.402 | Train/Valid accuracy: 0.828 / 0.813 | Train/Valid recall: 0.291 / 0.251 | \n",
            " Epoch 46 | Train/Valid loss: 0.380 / 0.404 | Train/Valid accuracy: 0.827 / 0.811 | Train/Valid recall: 0.305 / 0.222 | \n",
            " Epoch 47 | Train/Valid loss: 0.380 / 0.399 | Train/Valid accuracy: 0.829 / 0.804 | Train/Valid recall: 0.290 / 0.266 | \n",
            " Epoch 48 | Train/Valid loss: 0.380 / 0.400 | Train/Valid accuracy: 0.825 / 0.810 | Train/Valid recall: 0.305 / 0.256 | \n",
            " Epoch 49 | Train/Valid loss: 0.380 / 0.398 | Train/Valid accuracy: 0.827 / 0.807 | Train/Valid recall: 0.291 / 0.271 | \n",
            " Epoch 50 | Train/Valid loss: 0.379 / 0.401 | Train/Valid accuracy: 0.827 / 0.814 | Train/Valid recall: 0.303 / 0.246 | \n",
            " Epoch 51 | Train/Valid loss: 0.379 / 0.400 | Train/Valid accuracy: 0.828 / 0.812 | Train/Valid recall: 0.303 / 0.246 | \n",
            " Epoch 52 | Train/Valid loss: 0.379 / 0.398 | Train/Valid accuracy: 0.828 / 0.805 | Train/Valid recall: 0.297 / 0.266 | \n",
            " Epoch 53 | Train/Valid loss: 0.378 / 0.399 | Train/Valid accuracy: 0.829 / 0.810 | Train/Valid recall: 0.309 / 0.251 | \n",
            " Epoch 54 | Train/Valid loss: 0.378 / 0.397 | Train/Valid accuracy: 0.827 / 0.806 | Train/Valid recall: 0.290 / 0.266 | \n",
            " Epoch 55 | Train/Valid loss: 0.378 / 0.398 | Train/Valid accuracy: 0.827 / 0.809 | Train/Valid recall: 0.304 / 0.256 | \n",
            " Epoch 56 | Train/Valid loss: 0.378 / 0.400 | Train/Valid accuracy: 0.827 / 0.811 | Train/Valid recall: 0.296 / 0.246 | \n",
            " Epoch 57 | Train/Valid loss: 0.377 / 0.397 | Train/Valid accuracy: 0.829 / 0.808 | Train/Valid recall: 0.310 / 0.266 | \n",
            " Epoch 58 | Train/Valid loss: 0.377 / 0.401 | Train/Valid accuracy: 0.827 / 0.814 | Train/Valid recall: 0.309 / 0.242 | \n",
            " Epoch 59 | Train/Valid loss: 0.377 / 0.397 | Train/Valid accuracy: 0.828 / 0.809 | Train/Valid recall: 0.299 / 0.266 | \n",
            " Epoch 60 | Train/Valid loss: 0.377 / 0.395 | Train/Valid accuracy: 0.827 / 0.806 | Train/Valid recall: 0.299 / 0.280 | \n",
            " Epoch 61 | Train/Valid loss: 0.377 / 0.397 | Train/Valid accuracy: 0.828 / 0.809 | Train/Valid recall: 0.311 / 0.256 | \n",
            " Epoch 62 | Train/Valid loss: 0.376 / 0.396 | Train/Valid accuracy: 0.827 / 0.811 | Train/Valid recall: 0.301 / 0.256 | \n",
            " Epoch 63 | Train/Valid loss: 0.376 / 0.394 | Train/Valid accuracy: 0.827 / 0.806 | Train/Valid recall: 0.300 / 0.285 | \n",
            " Epoch 64 | Train/Valid loss: 0.376 / 0.395 | Train/Valid accuracy: 0.828 / 0.806 | Train/Valid recall: 0.312 / 0.271 | \n",
            " Epoch 65 | Train/Valid loss: 0.375 / 0.396 | Train/Valid accuracy: 0.829 / 0.807 | Train/Valid recall: 0.303 / 0.261 | \n",
            " Epoch 66 | Train/Valid loss: 0.375 / 0.395 | Train/Valid accuracy: 0.828 / 0.805 | Train/Valid recall: 0.302 / 0.261 | \n",
            " Epoch 67 | Train/Valid loss: 0.375 / 0.399 | Train/Valid accuracy: 0.828 / 0.816 | Train/Valid recall: 0.318 / 0.246 | \n",
            " Epoch 68 | Train/Valid loss: 0.375 / 0.398 | Train/Valid accuracy: 0.831 / 0.820 | Train/Valid recall: 0.312 / 0.251 | \n",
            " Epoch 69 | Train/Valid loss: 0.375 / 0.393 | Train/Valid accuracy: 0.829 / 0.806 | Train/Valid recall: 0.301 / 0.300 | \n",
            " Epoch 70 | Train/Valid loss: 0.375 / 0.394 | Train/Valid accuracy: 0.829 / 0.809 | Train/Valid recall: 0.309 / 0.261 | \n",
            " Epoch 71 | Train/Valid loss: 0.374 / 0.398 | Train/Valid accuracy: 0.829 / 0.818 | Train/Valid recall: 0.319 / 0.246 | \n",
            " Epoch 72 | Train/Valid loss: 0.375 / 0.392 | Train/Valid accuracy: 0.829 / 0.806 | Train/Valid recall: 0.310 / 0.300 | \n",
            " Epoch 73 | Train/Valid loss: 0.374 / 0.394 | Train/Valid accuracy: 0.831 / 0.811 | Train/Valid recall: 0.313 / 0.261 | \n",
            " Epoch 74 | Train/Valid loss: 0.373 / 0.395 | Train/Valid accuracy: 0.828 / 0.812 | Train/Valid recall: 0.315 / 0.261 | \n",
            " Epoch 75 | Train/Valid loss: 0.373 / 0.394 | Train/Valid accuracy: 0.828 / 0.812 | Train/Valid recall: 0.305 / 0.261 | \n",
            " Epoch 76 | Train/Valid loss: 0.373 / 0.396 | Train/Valid accuracy: 0.829 / 0.819 | Train/Valid recall: 0.317 / 0.261 | \n",
            " Epoch 77 | Train/Valid loss: 0.373 / 0.394 | Train/Valid accuracy: 0.829 / 0.818 | Train/Valid recall: 0.312 / 0.261 | \n",
            " Epoch 78 | Train/Valid loss: 0.373 / 0.397 | Train/Valid accuracy: 0.831 / 0.821 | Train/Valid recall: 0.316 / 0.251 | \n",
            " Epoch 79 | Train/Valid loss: 0.372 / 0.394 | Train/Valid accuracy: 0.830 / 0.818 | Train/Valid recall: 0.313 / 0.261 | \n",
            " Epoch 80 | Train/Valid loss: 0.373 / 0.390 | Train/Valid accuracy: 0.830 / 0.807 | Train/Valid recall: 0.310 / 0.324 | \n",
            " Epoch 81 | Train/Valid loss: 0.372 / 0.391 | Train/Valid accuracy: 0.830 / 0.805 | Train/Valid recall: 0.324 / 0.285 | \n",
            " Epoch 82 | Train/Valid loss: 0.371 / 0.401 | Train/Valid accuracy: 0.831 / 0.818 | Train/Valid recall: 0.332 / 0.217 | \n",
            " Epoch 83 | Train/Valid loss: 0.372 / 0.396 | Train/Valid accuracy: 0.829 / 0.820 | Train/Valid recall: 0.300 / 0.256 | \n",
            " Epoch 84 | Train/Valid loss: 0.371 / 0.391 | Train/Valid accuracy: 0.830 / 0.806 | Train/Valid recall: 0.315 / 0.275 | \n",
            " Epoch 85 | Train/Valid loss: 0.371 / 0.393 | Train/Valid accuracy: 0.829 / 0.814 | Train/Valid recall: 0.319 / 0.261 | \n",
            " Epoch 86 | Train/Valid loss: 0.371 / 0.389 | Train/Valid accuracy: 0.830 / 0.807 | Train/Valid recall: 0.320 / 0.324 | \n",
            " Epoch 87 | Train/Valid loss: 0.371 / 0.392 | Train/Valid accuracy: 0.830 / 0.814 | Train/Valid recall: 0.320 / 0.266 | \n",
            " Epoch 88 | Train/Valid loss: 0.371 / 0.390 | Train/Valid accuracy: 0.830 / 0.810 | Train/Valid recall: 0.316 / 0.280 | \n",
            " Epoch 89 | Train/Valid loss: 0.370 / 0.391 | Train/Valid accuracy: 0.832 / 0.815 | Train/Valid recall: 0.322 / 0.275 | \n",
            " Epoch 90 | Train/Valid loss: 0.370 / 0.388 | Train/Valid accuracy: 0.831 / 0.807 | Train/Valid recall: 0.310 / 0.319 | \n",
            " Epoch 91 | Train/Valid loss: 0.370 / 0.389 | Train/Valid accuracy: 0.829 / 0.808 | Train/Valid recall: 0.320 / 0.300 | \n",
            " Epoch 92 | Train/Valid loss: 0.369 / 0.388 | Train/Valid accuracy: 0.832 / 0.805 | Train/Valid recall: 0.318 / 0.333 | \n",
            " Epoch 93 | Train/Valid loss: 0.369 / 0.392 | Train/Valid accuracy: 0.832 / 0.816 | Train/Valid recall: 0.340 / 0.261 | \n",
            " Epoch 94 | Train/Valid loss: 0.369 / 0.392 | Train/Valid accuracy: 0.831 / 0.819 | Train/Valid recall: 0.321 / 0.261 | \n",
            " Epoch 95 | Train/Valid loss: 0.369 / 0.389 | Train/Valid accuracy: 0.831 / 0.812 | Train/Valid recall: 0.320 / 0.275 | \n",
            " Epoch 96 | Train/Valid loss: 0.369 / 0.389 | Train/Valid accuracy: 0.831 / 0.811 | Train/Valid recall: 0.327 / 0.275 | \n",
            " Epoch 97 | Train/Valid loss: 0.369 / 0.388 | Train/Valid accuracy: 0.832 / 0.811 | Train/Valid recall: 0.319 / 0.280 | \n",
            " Epoch 98 | Train/Valid loss: 0.368 / 0.387 | Train/Valid accuracy: 0.830 / 0.809 | Train/Valid recall: 0.325 / 0.304 | \n",
            " Epoch 99 | Train/Valid loss: 0.368 / 0.395 | Train/Valid accuracy: 0.831 / 0.823 | Train/Valid recall: 0.336 / 0.251 | \n"
          ]
        }
      ],
      "source": [
        "# cantidad de epochs\n",
        "epochs = 100\n",
        "\n",
        "# Doble loop algoritmo Mini-Batch\n",
        "for epoch in range(epochs):\n",
        "  \n",
        "  ############################################\n",
        "  ## Entrenamiento\n",
        "  ############################################\n",
        "  nnet.train(True)\n",
        "\n",
        "  epoch_loss = 0\n",
        "  epoch_y_hat = []\n",
        "  epoch_y = []\n",
        "  \n",
        "  for i,data in enumerate(train_dataloader):\n",
        "    # Obtengo los datos del batch de entrenamiento\n",
        "    x_batch, y_batch = data\n",
        "    # Copio el batch al dispositivo donde entreno la red neuronal\n",
        "    x_batch = x_batch.to(device).float()\n",
        "    y_batch = y_batch.to(device).float().reshape(-1, 1)\n",
        "\n",
        "    # Paso forward\n",
        "    # Limpio optimizer para empezar un nuevo c√°lculo de gradiente\n",
        "    optimizer.zero_grad()\n",
        "    y_batch_hat = nnet(x_batch)\n",
        "    \n",
        "    # Calculo el loss\n",
        "    loss = loss_function(y_batch_hat, y_batch)\n",
        "\n",
        "    # Backpropagation\n",
        "    loss.backward()\n",
        "\n",
        "    # Actualizar los par√°metros\n",
        "    optimizer.step()\n",
        "\n",
        "    # Almaceno los valores reales y mis predicciones para c√°lcular las m√©tricas\n",
        "    epoch_y += list(y_batch.detach().cpu().numpy())\n",
        "    epoch_y_hat += list(y_batch_hat.detach().cpu().numpy())\n",
        "    # Acumulo la loss del batch\n",
        "    epoch_loss = epoch_loss + loss.item()\n",
        "\n",
        "  # Calculo la media de la loss\n",
        "  epoch_loss = epoch_loss / n_train\n",
        "  # C√°lculo la m√©trica de la epoch\n",
        "  accuracy = metrics.accuracy_score(epoch_y, [j>=0.5 for j in epoch_y_hat])\n",
        "  recall = metrics.recall_score(epoch_y, [j>=0.5 for j in epoch_y_hat])\n",
        "\n",
        "  ############################################\n",
        "  ## Validaci√≥n\n",
        "  ############################################\n",
        "  # Desactivo el c√°lculo de gradiente para validaci√≥n\n",
        "  nnet.train(False)\n",
        "\n",
        "  valid_epoch_loss = 0\n",
        "  valid_epoch_y_hat = []\n",
        "  valid_epoch_y = []\n",
        "\n",
        "  for i,data in enumerate(valid_dataloader):\n",
        "    # Obtengo los datos del batch de validaci√≥n\n",
        "    x_batch, y_batch = data\n",
        "    # Copio el batch al dispositivo donde entreno la red neuronal\n",
        "    x_batch = x_batch.to(device).float()\n",
        "    y_batch = y_batch.to(device).float().reshape(-1, 1)\n",
        "\n",
        "    # Paso forward\n",
        "    y_batch_hat = nnet(x_batch)\n",
        "    \n",
        "    # Calculo el loss\n",
        "    loss = loss_function(y_batch_hat, y_batch)\n",
        "\n",
        "    # En validaci√≥n no hago backpropagation!!\n",
        "\n",
        "    # Almaceno los valores reales y mis predicciones para c√°lcular las m√©tricas\n",
        "    valid_epoch_y += list(y_batch.detach().cpu().numpy())\n",
        "    valid_epoch_y_hat += list(y_batch_hat.detach().cpu().numpy())\n",
        "    # Acumulo la loss del batch\n",
        "    valid_epoch_loss = valid_epoch_loss + loss.item()\n",
        "\n",
        "  # Calculo la media de la loss\n",
        "  valid_epoch_loss = valid_epoch_loss / n_valid\n",
        "  # C√°lculo la m√©trica de la epoch\n",
        "  valid_accuracy = metrics.accuracy_score(valid_epoch_y, [j>=0.5 for j in valid_epoch_y_hat])\n",
        "  valid_recall = metrics.recall_score(valid_epoch_y, [j>=0.5 for j in valid_epoch_y_hat])\n",
        "\n",
        "  ############################################\n",
        "  ## Impresi√≥n de resultados por epoch\n",
        "  ############################################\n",
        "  print(f\" Epoch {epoch} | \" \\\n",
        "        f\"Train/Valid loss: {epoch_loss:.3f} / {valid_epoch_loss:.3f} | \" \\\n",
        "        f\"Train/Valid accuracy: {accuracy:.3f} / {valid_accuracy:.3f} | \" \\\n",
        "        f\"Train/Valid recall: {recall:.3f} / {valid_recall:.3f} | \")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hjqN0xV9oL8r"
      },
      "source": [
        "Si bien el accuracy es alto, el recall (que mide el porcentaje de vinos buenos clasificados como buenos) es muy bajo. Esto se debe al desbalance entre las clases "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VHiwQsa0oW54"
      },
      "source": [
        "#### Entrenamiento con loss custom"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qIxq7cfEMY2F"
      },
      "outputs": [],
      "source": [
        "# La funci√≥n de costo custom se define como la red neuronal, extendiendo la \n",
        "# clase torch.nn.Module\n",
        "class CustomLoss(torch.nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.criterion = torch.nn.BCELoss()\n",
        "    pass\n",
        "\n",
        "  # En el paso forward se aplica el algoritmo de la funci√≥n de perdida\n",
        "  # y se retorna el valor escalar de p√©rdida.\n",
        "  def forward(self, output, target):\n",
        "    bce = self.criterion(output, target)\n",
        "    tp = (output * target).sum()\n",
        "    fn = ((1- output) * target).sum()\n",
        "    recall = tp / ((tp + fn))\n",
        "    return bce - recall"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h8I1yic1oc_a"
      },
      "source": [
        "La loss anterior es inventada, es una mezcla de BinaryCrossEntropy y una aproximaci√≥n con derivada continua del recall. \n",
        "\n",
        "El signo menos antes del recall en el c√°lculo de la p√©rdida es porque el algoritmo de optimizaci√≥n busca minimizar la funci√≥n de p√©rdida, pero nosotros deseamos maximizar el recall."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j_1DLLpHipbe"
      },
      "outputs": [],
      "source": [
        "# Instanciamos la red\n",
        "nnet = NNet()\n",
        "# Copio la red neuronal al dispositivo donde entrene la red neuronal\n",
        "nnet = nnet.to(device)\n",
        "# Loss custom\n",
        "loss_function = CustomLoss()\n",
        "# Optimizer\n",
        "optimizer = torch.optim.Adam(nnet.parameters(), lr=0.0001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nY5THc5diw_L",
        "outputId": "c6e944d9-2254-4be8-91fc-5a0a0cb4dbc7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Epoch 0 | Train/Valid loss: 0.003 / 0.003 | Train/Valid accuracy: 0.553 / 0.800 | Train/Valid recall: 0.562 / 0.063 | \n",
            " Epoch 1 | Train/Valid loss: 0.003 / 0.003 | Train/Valid accuracy: 0.809 / 0.787 | Train/Valid recall: 0.175 / 0.353 | \n",
            " Epoch 2 | Train/Valid loss: 0.002 / 0.002 | Train/Valid accuracy: 0.777 / 0.759 | Train/Valid recall: 0.482 / 0.541 | \n",
            " Epoch 3 | Train/Valid loss: 0.001 / 0.001 | Train/Valid accuracy: 0.745 / 0.744 | Train/Valid recall: 0.598 / 0.585 | \n",
            " Epoch 4 | Train/Valid loss: 0.000 / -0.000 | Train/Valid accuracy: 0.739 / 0.742 | Train/Valid recall: 0.648 / 0.623 | \n",
            " Epoch 5 | Train/Valid loss: -0.000 / -0.001 | Train/Valid accuracy: 0.745 / 0.753 | Train/Valid recall: 0.665 / 0.614 | \n",
            " Epoch 6 | Train/Valid loss: -0.001 / -0.001 | Train/Valid accuracy: 0.747 / 0.745 | Train/Valid recall: 0.670 / 0.681 | \n",
            " Epoch 7 | Train/Valid loss: -0.001 / -0.001 | Train/Valid accuracy: 0.749 / 0.757 | Train/Valid recall: 0.691 / 0.662 | \n",
            " Epoch 8 | Train/Valid loss: -0.001 / -0.002 | Train/Valid accuracy: 0.749 / 0.756 | Train/Valid recall: 0.696 / 0.671 | \n",
            " Epoch 9 | Train/Valid loss: -0.001 / -0.002 | Train/Valid accuracy: 0.750 / 0.759 | Train/Valid recall: 0.700 / 0.671 | \n",
            " Epoch 10 | Train/Valid loss: -0.002 / -0.002 | Train/Valid accuracy: 0.749 / 0.759 | Train/Valid recall: 0.703 / 0.681 | \n",
            " Epoch 11 | Train/Valid loss: -0.002 / -0.002 | Train/Valid accuracy: 0.751 / 0.762 | Train/Valid recall: 0.697 / 0.686 | \n",
            " Epoch 12 | Train/Valid loss: -0.002 / -0.002 | Train/Valid accuracy: 0.752 / 0.757 | Train/Valid recall: 0.711 / 0.696 | \n",
            " Epoch 13 | Train/Valid loss: -0.002 / -0.002 | Train/Valid accuracy: 0.752 / 0.764 | Train/Valid recall: 0.713 / 0.691 | \n",
            " Epoch 14 | Train/Valid loss: -0.002 / -0.002 | Train/Valid accuracy: 0.752 / 0.762 | Train/Valid recall: 0.725 / 0.696 | \n",
            " Epoch 15 | Train/Valid loss: -0.002 / -0.002 | Train/Valid accuracy: 0.750 / 0.768 | Train/Valid recall: 0.724 / 0.681 | \n",
            " Epoch 16 | Train/Valid loss: -0.002 / -0.002 | Train/Valid accuracy: 0.758 / 0.753 | Train/Valid recall: 0.717 / 0.696 | \n",
            " Epoch 17 | Train/Valid loss: -0.002 / -0.002 | Train/Valid accuracy: 0.748 / 0.757 | Train/Valid recall: 0.727 / 0.686 | \n",
            " Epoch 18 | Train/Valid loss: -0.002 / -0.002 | Train/Valid accuracy: 0.754 / 0.752 | Train/Valid recall: 0.720 / 0.715 | \n",
            " Epoch 19 | Train/Valid loss: -0.002 / -0.002 | Train/Valid accuracy: 0.750 / 0.773 | Train/Valid recall: 0.727 / 0.686 | \n",
            " Epoch 20 | Train/Valid loss: -0.002 / -0.002 | Train/Valid accuracy: 0.751 / 0.774 | Train/Valid recall: 0.733 / 0.676 | \n",
            " Epoch 21 | Train/Valid loss: -0.002 / -0.002 | Train/Valid accuracy: 0.754 / 0.762 | Train/Valid recall: 0.730 / 0.691 | \n",
            " Epoch 22 | Train/Valid loss: -0.002 / -0.002 | Train/Valid accuracy: 0.750 / 0.770 | Train/Valid recall: 0.734 / 0.691 | \n",
            " Epoch 23 | Train/Valid loss: -0.002 / -0.002 | Train/Valid accuracy: 0.757 / 0.758 | Train/Valid recall: 0.735 / 0.691 | \n",
            " Epoch 24 | Train/Valid loss: -0.002 / -0.002 | Train/Valid accuracy: 0.753 / 0.754 | Train/Valid recall: 0.730 / 0.705 | \n",
            " Epoch 25 | Train/Valid loss: -0.002 / -0.002 | Train/Valid accuracy: 0.754 / 0.757 | Train/Valid recall: 0.737 / 0.691 | \n",
            " Epoch 26 | Train/Valid loss: -0.002 / -0.002 | Train/Valid accuracy: 0.751 / 0.756 | Train/Valid recall: 0.730 / 0.691 | \n",
            " Epoch 27 | Train/Valid loss: -0.002 / -0.002 | Train/Valid accuracy: 0.749 / 0.769 | Train/Valid recall: 0.744 / 0.686 | \n",
            " Epoch 28 | Train/Valid loss: -0.002 / -0.002 | Train/Valid accuracy: 0.754 / 0.753 | Train/Valid recall: 0.725 / 0.720 | \n",
            " Epoch 29 | Train/Valid loss: -0.002 / -0.002 | Train/Valid accuracy: 0.755 / 0.766 | Train/Valid recall: 0.739 / 0.691 | \n",
            " Epoch 30 | Train/Valid loss: -0.002 / -0.002 | Train/Valid accuracy: 0.752 / 0.776 | Train/Valid recall: 0.743 / 0.681 | \n",
            " Epoch 31 | Train/Valid loss: -0.002 / -0.002 | Train/Valid accuracy: 0.754 / 0.760 | Train/Valid recall: 0.733 / 0.691 | \n",
            " Epoch 32 | Train/Valid loss: -0.002 / -0.002 | Train/Valid accuracy: 0.753 / 0.766 | Train/Valid recall: 0.743 / 0.691 | \n",
            " Epoch 33 | Train/Valid loss: -0.002 / -0.003 | Train/Valid accuracy: 0.754 / 0.762 | Train/Valid recall: 0.735 / 0.691 | \n",
            " Epoch 34 | Train/Valid loss: -0.002 / -0.003 | Train/Valid accuracy: 0.753 / 0.762 | Train/Valid recall: 0.738 / 0.691 | \n",
            " Epoch 35 | Train/Valid loss: -0.002 / -0.003 | Train/Valid accuracy: 0.754 / 0.765 | Train/Valid recall: 0.741 / 0.681 | \n",
            " Epoch 36 | Train/Valid loss: -0.002 / -0.003 | Train/Valid accuracy: 0.755 / 0.764 | Train/Valid recall: 0.738 / 0.686 | \n",
            " Epoch 37 | Train/Valid loss: -0.002 / -0.003 | Train/Valid accuracy: 0.754 / 0.761 | Train/Valid recall: 0.737 / 0.696 | \n",
            " Epoch 38 | Train/Valid loss: -0.002 / -0.003 | Train/Valid accuracy: 0.757 / 0.763 | Train/Valid recall: 0.730 / 0.696 | \n",
            " Epoch 39 | Train/Valid loss: -0.002 / -0.002 | Train/Valid accuracy: 0.753 / 0.775 | Train/Valid recall: 0.746 / 0.671 | \n",
            " Epoch 40 | Train/Valid loss: -0.002 / -0.003 | Train/Valid accuracy: 0.758 / 0.757 | Train/Valid recall: 0.738 / 0.710 | \n",
            " Epoch 41 | Train/Valid loss: -0.002 / -0.003 | Train/Valid accuracy: 0.753 / 0.772 | Train/Valid recall: 0.745 / 0.676 | \n",
            " Epoch 42 | Train/Valid loss: -0.002 / -0.003 | Train/Valid accuracy: 0.757 / 0.763 | Train/Valid recall: 0.730 / 0.700 | \n",
            " Epoch 43 | Train/Valid loss: -0.002 / -0.003 | Train/Valid accuracy: 0.752 / 0.769 | Train/Valid recall: 0.750 / 0.676 | \n",
            " Epoch 44 | Train/Valid loss: -0.002 / -0.003 | Train/Valid accuracy: 0.758 / 0.766 | Train/Valid recall: 0.743 / 0.681 | \n",
            " Epoch 45 | Train/Valid loss: -0.002 / -0.003 | Train/Valid accuracy: 0.757 / 0.764 | Train/Valid recall: 0.742 / 0.681 | \n",
            " Epoch 46 | Train/Valid loss: -0.002 / -0.003 | Train/Valid accuracy: 0.754 / 0.761 | Train/Valid recall: 0.741 / 0.691 | \n",
            " Epoch 47 | Train/Valid loss: -0.002 / -0.003 | Train/Valid accuracy: 0.755 / 0.773 | Train/Valid recall: 0.741 / 0.676 | \n",
            " Epoch 48 | Train/Valid loss: -0.002 / -0.003 | Train/Valid accuracy: 0.758 / 0.754 | Train/Valid recall: 0.737 / 0.705 | \n",
            " Epoch 49 | Train/Valid loss: -0.002 / -0.003 | Train/Valid accuracy: 0.754 / 0.764 | Train/Valid recall: 0.742 / 0.686 | \n",
            " Epoch 50 | Train/Valid loss: -0.002 / -0.003 | Train/Valid accuracy: 0.756 / 0.772 | Train/Valid recall: 0.742 / 0.681 | \n",
            " Epoch 51 | Train/Valid loss: -0.002 / -0.003 | Train/Valid accuracy: 0.756 / 0.760 | Train/Valid recall: 0.747 / 0.691 | \n",
            " Epoch 52 | Train/Valid loss: -0.002 / -0.003 | Train/Valid accuracy: 0.757 / 0.756 | Train/Valid recall: 0.744 / 0.700 | \n",
            " Epoch 53 | Train/Valid loss: -0.002 / -0.003 | Train/Valid accuracy: 0.754 / 0.757 | Train/Valid recall: 0.745 / 0.691 | \n",
            " Epoch 54 | Train/Valid loss: -0.002 / -0.003 | Train/Valid accuracy: 0.755 / 0.763 | Train/Valid recall: 0.746 / 0.686 | \n",
            " Epoch 55 | Train/Valid loss: -0.002 / -0.003 | Train/Valid accuracy: 0.756 / 0.765 | Train/Valid recall: 0.742 / 0.686 | \n",
            " Epoch 56 | Train/Valid loss: -0.002 / -0.003 | Train/Valid accuracy: 0.756 / 0.753 | Train/Valid recall: 0.744 / 0.700 | \n",
            " Epoch 57 | Train/Valid loss: -0.002 / -0.003 | Train/Valid accuracy: 0.757 / 0.774 | Train/Valid recall: 0.747 / 0.686 | \n",
            " Epoch 58 | Train/Valid loss: -0.002 / -0.003 | Train/Valid accuracy: 0.757 / 0.763 | Train/Valid recall: 0.745 / 0.691 | \n",
            " Epoch 59 | Train/Valid loss: -0.002 / -0.003 | Train/Valid accuracy: 0.756 / 0.756 | Train/Valid recall: 0.740 / 0.691 | \n",
            " Epoch 60 | Train/Valid loss: -0.002 / -0.003 | Train/Valid accuracy: 0.754 / 0.761 | Train/Valid recall: 0.746 / 0.691 | \n",
            " Epoch 61 | Train/Valid loss: -0.003 / -0.003 | Train/Valid accuracy: 0.758 / 0.765 | Train/Valid recall: 0.747 / 0.686 | \n",
            " Epoch 62 | Train/Valid loss: -0.002 / -0.003 | Train/Valid accuracy: 0.759 / 0.759 | Train/Valid recall: 0.742 / 0.691 | \n",
            " Epoch 63 | Train/Valid loss: -0.002 / -0.003 | Train/Valid accuracy: 0.754 / 0.774 | Train/Valid recall: 0.755 / 0.686 | \n",
            " Epoch 64 | Train/Valid loss: -0.003 / -0.003 | Train/Valid accuracy: 0.761 / 0.766 | Train/Valid recall: 0.742 / 0.691 | \n",
            " Epoch 65 | Train/Valid loss: -0.002 / -0.003 | Train/Valid accuracy: 0.756 / 0.757 | Train/Valid recall: 0.747 / 0.691 | \n",
            " Epoch 66 | Train/Valid loss: -0.003 / -0.003 | Train/Valid accuracy: 0.757 / 0.766 | Train/Valid recall: 0.744 / 0.691 | \n",
            " Epoch 67 | Train/Valid loss: -0.003 / -0.003 | Train/Valid accuracy: 0.758 / 0.759 | Train/Valid recall: 0.745 / 0.691 | \n",
            " Epoch 68 | Train/Valid loss: -0.003 / -0.003 | Train/Valid accuracy: 0.757 / 0.760 | Train/Valid recall: 0.741 / 0.691 | \n",
            " Epoch 69 | Train/Valid loss: -0.003 / -0.003 | Train/Valid accuracy: 0.757 / 0.766 | Train/Valid recall: 0.744 / 0.691 | \n",
            " Epoch 70 | Train/Valid loss: -0.003 / -0.003 | Train/Valid accuracy: 0.757 / 0.754 | Train/Valid recall: 0.742 / 0.696 | \n",
            " Epoch 71 | Train/Valid loss: -0.003 / -0.003 | Train/Valid accuracy: 0.757 / 0.753 | Train/Valid recall: 0.744 / 0.691 | \n",
            " Epoch 72 | Train/Valid loss: -0.003 / -0.003 | Train/Valid accuracy: 0.756 / 0.777 | Train/Valid recall: 0.751 / 0.686 | \n",
            " Epoch 73 | Train/Valid loss: -0.003 / -0.003 | Train/Valid accuracy: 0.759 / 0.774 | Train/Valid recall: 0.745 / 0.686 | \n",
            " Epoch 74 | Train/Valid loss: -0.003 / -0.003 | Train/Valid accuracy: 0.758 / 0.778 | Train/Valid recall: 0.742 / 0.686 | \n",
            " Epoch 75 | Train/Valid loss: -0.003 / -0.003 | Train/Valid accuracy: 0.761 / 0.768 | Train/Valid recall: 0.742 / 0.696 | \n",
            " Epoch 76 | Train/Valid loss: -0.003 / -0.003 | Train/Valid accuracy: 0.756 / 0.768 | Train/Valid recall: 0.749 / 0.691 | \n",
            " Epoch 77 | Train/Valid loss: -0.003 / -0.003 | Train/Valid accuracy: 0.762 / 0.762 | Train/Valid recall: 0.742 / 0.691 | \n",
            " Epoch 78 | Train/Valid loss: -0.003 / -0.003 | Train/Valid accuracy: 0.756 / 0.768 | Train/Valid recall: 0.751 / 0.691 | \n",
            " Epoch 79 | Train/Valid loss: -0.003 / -0.003 | Train/Valid accuracy: 0.759 / 0.771 | Train/Valid recall: 0.741 / 0.696 | \n",
            " Epoch 80 | Train/Valid loss: -0.003 / -0.003 | Train/Valid accuracy: 0.759 / 0.764 | Train/Valid recall: 0.744 / 0.696 | \n",
            " Epoch 81 | Train/Valid loss: -0.003 / -0.003 | Train/Valid accuracy: 0.759 / 0.779 | Train/Valid recall: 0.748 / 0.691 | \n",
            " Epoch 82 | Train/Valid loss: -0.003 / -0.003 | Train/Valid accuracy: 0.760 / 0.755 | Train/Valid recall: 0.743 / 0.705 | \n",
            " Epoch 83 | Train/Valid loss: -0.003 / -0.003 | Train/Valid accuracy: 0.759 / 0.757 | Train/Valid recall: 0.739 / 0.696 | \n",
            " Epoch 84 | Train/Valid loss: -0.003 / -0.003 | Train/Valid accuracy: 0.758 / 0.762 | Train/Valid recall: 0.743 / 0.696 | \n",
            " Epoch 85 | Train/Valid loss: -0.003 / -0.003 | Train/Valid accuracy: 0.760 / 0.771 | Train/Valid recall: 0.742 / 0.696 | \n",
            " Epoch 86 | Train/Valid loss: -0.003 / -0.003 | Train/Valid accuracy: 0.766 / 0.758 | Train/Valid recall: 0.745 / 0.705 | \n",
            " Epoch 87 | Train/Valid loss: -0.003 / -0.003 | Train/Valid accuracy: 0.758 / 0.773 | Train/Valid recall: 0.758 / 0.696 | \n",
            " Epoch 88 | Train/Valid loss: -0.003 / -0.003 | Train/Valid accuracy: 0.762 / 0.784 | Train/Valid recall: 0.748 / 0.696 | \n",
            " Epoch 89 | Train/Valid loss: -0.003 / -0.003 | Train/Valid accuracy: 0.765 / 0.762 | Train/Valid recall: 0.751 / 0.700 | \n",
            " Epoch 90 | Train/Valid loss: -0.003 / -0.003 | Train/Valid accuracy: 0.760 / 0.785 | Train/Valid recall: 0.755 / 0.691 | \n",
            " Epoch 91 | Train/Valid loss: -0.003 / -0.003 | Train/Valid accuracy: 0.761 / 0.788 | Train/Valid recall: 0.746 / 0.676 | \n",
            " Epoch 92 | Train/Valid loss: -0.003 / -0.003 | Train/Valid accuracy: 0.767 / 0.762 | Train/Valid recall: 0.742 / 0.696 | \n",
            " Epoch 93 | Train/Valid loss: -0.003 / -0.003 | Train/Valid accuracy: 0.760 / 0.788 | Train/Valid recall: 0.758 / 0.681 | \n",
            " Epoch 94 | Train/Valid loss: -0.003 / -0.003 | Train/Valid accuracy: 0.767 / 0.757 | Train/Valid recall: 0.745 / 0.705 | \n",
            " Epoch 95 | Train/Valid loss: -0.003 / -0.003 | Train/Valid accuracy: 0.764 / 0.774 | Train/Valid recall: 0.748 / 0.700 | \n",
            " Epoch 96 | Train/Valid loss: -0.003 / -0.003 | Train/Valid accuracy: 0.761 / 0.775 | Train/Valid recall: 0.752 / 0.696 | \n",
            " Epoch 97 | Train/Valid loss: -0.003 / -0.003 | Train/Valid accuracy: 0.765 / 0.767 | Train/Valid recall: 0.751 / 0.700 | \n",
            " Epoch 98 | Train/Valid loss: -0.003 / -0.003 | Train/Valid accuracy: 0.764 / 0.779 | Train/Valid recall: 0.749 / 0.700 | \n",
            " Epoch 99 | Train/Valid loss: -0.003 / -0.003 | Train/Valid accuracy: 0.764 / 0.785 | Train/Valid recall: 0.751 / 0.681 | \n"
          ]
        }
      ],
      "source": [
        "# cantidad de epochs\n",
        "epochs = 100\n",
        "\n",
        "# Doble loop algoritmo Mini-Batch\n",
        "for epoch in range(epochs):\n",
        "  \n",
        "  ############################################\n",
        "  ## Entrenamiento\n",
        "  ############################################\n",
        "  nnet.train(True)\n",
        "\n",
        "  epoch_loss = 0\n",
        "  epoch_y_hat = []\n",
        "  epoch_y = []\n",
        "  \n",
        "  for i,data in enumerate(train_dataloader):\n",
        "    # Obtengo los datos del batch de entrenamiento\n",
        "    x_batch, y_batch = data\n",
        "    # Copio el batch al dispositivo donde entreno la red neuronal\n",
        "    x_batch = x_batch.to(device).float()\n",
        "    y_batch = y_batch.to(device).float().reshape(-1, 1)\n",
        "\n",
        "    # Paso forward\n",
        "    # Limpio optimizer para empezar un nuevo c√°lculo de gradiente\n",
        "    optimizer.zero_grad()\n",
        "    y_batch_hat = nnet(x_batch)\n",
        "    \n",
        "    # Calculo el loss\n",
        "    loss = loss_function(y_batch_hat, y_batch)\n",
        "\n",
        "    # Backpropagation\n",
        "    loss.backward()\n",
        "\n",
        "    # Actualizar los par√°metros\n",
        "    optimizer.step()\n",
        "\n",
        "    # Almaceno los valores reales y mis predicciones para c√°lcular las m√©tricas\n",
        "    epoch_y += list(y_batch.detach().cpu().numpy())\n",
        "    epoch_y_hat += list(y_batch_hat.detach().cpu().numpy())\n",
        "    # Acumulo la loss del batch\n",
        "    epoch_loss = epoch_loss + loss.item()\n",
        "\n",
        "  # Calculo la media de la loss\n",
        "  epoch_loss = epoch_loss / n_train\n",
        "  # C√°lculo la m√©trica de la epoch\n",
        "  accuracy = metrics.accuracy_score(epoch_y, [j>=0.5 for j in epoch_y_hat])\n",
        "  recall = metrics.recall_score(epoch_y, [j>=0.5 for j in epoch_y_hat])\n",
        "\n",
        "  ############################################\n",
        "  ## Validaci√≥n\n",
        "  ############################################\n",
        "  # Desactivo el c√°lculo de gradiente para validaci√≥n\n",
        "  nnet.train(False)\n",
        "\n",
        "  valid_epoch_loss = 0\n",
        "  valid_epoch_y_hat = []\n",
        "  valid_epoch_y = []\n",
        "\n",
        "  for i,data in enumerate(valid_dataloader):\n",
        "    # Obtengo los datos del batch de validaci√≥n\n",
        "    x_batch, y_batch = data\n",
        "    # Copio el batch al dispositivo donde entreno la red neuronal\n",
        "    x_batch = x_batch.to(device).float()\n",
        "    y_batch = y_batch.to(device).float().reshape(-1, 1)\n",
        "\n",
        "    # Paso forward\n",
        "    y_batch_hat = nnet(x_batch)\n",
        "    \n",
        "    # Calculo el loss\n",
        "    loss = loss_function(y_batch_hat, y_batch)\n",
        "\n",
        "    # En validaci√≥n no hago backpropagation!!\n",
        "\n",
        "    # Almaceno los valores reales y mis predicciones para c√°lcular las m√©tricas\n",
        "    valid_epoch_y += list(y_batch.detach().cpu().numpy())\n",
        "    valid_epoch_y_hat += list(y_batch_hat.detach().cpu().numpy())\n",
        "    # Acumulo la loss del batch\n",
        "    valid_epoch_loss = valid_epoch_loss + loss.item()\n",
        "\n",
        "  # Calculo la media de la loss\n",
        "  valid_epoch_loss = valid_epoch_loss / n_valid\n",
        "  # C√°lculo la m√©trica de la epoch\n",
        "  valid_accuracy = metrics.accuracy_score(valid_epoch_y, [j>=0.5 for j in valid_epoch_y_hat])\n",
        "  valid_recall = metrics.recall_score(valid_epoch_y, [j>=0.5 for j in valid_epoch_y_hat])\n",
        "\n",
        "  ############################################\n",
        "  ## Impresi√≥n de resultados por epoch\n",
        "  ############################################\n",
        "  print(f\" Epoch {epoch} | \" \\\n",
        "        f\"Train/Valid loss: {epoch_loss:.3f} / {valid_epoch_loss:.3f} | \" \\\n",
        "        f\"Train/Valid accuracy: {accuracy:.3f} / {valid_accuracy:.3f} | \" \\\n",
        "        f\"Train/Valid recall: {recall:.3f} / {valid_recall:.3f} | \")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wxEZFv5Uow37"
      },
      "source": [
        "El accuracy es menor (lo cual es esperable ya que estamos imponiendo restricciones adicionales a la funci√≥n de costo) pero se logr√≥ un recall marcadamente mayor.\n",
        "\n",
        "Con que modelo nos quedamos depende de las necesidades del problema."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
