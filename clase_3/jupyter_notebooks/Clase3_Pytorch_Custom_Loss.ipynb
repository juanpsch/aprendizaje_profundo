{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6hnAb_E0gZFA"
      },
      "source": [
        "# Aprendizaje Profundo - Clase 3  - Custom Loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "TUEjdowba98t"
      },
      "outputs": [],
      "source": [
        "# Importo librerías\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fVMKJ1DihXiv"
      },
      "source": [
        "## Cargamos el dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "dF9wgHw5jTW8"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/drive/MyDrive/Trabajo AP/Material/class_7_wine_dataset_v2.csv'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32md:\\Users\\juanp_schamun\\Documents\\GitRepositories\\CEIA\\aprendizaje_profundo\\clase_3\\jupyter_notebooks\\Clase3_Pytorch_Custom_Loss.ipynb Cell 4\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Users/juanp_schamun/Documents/GitRepositories/CEIA/aprendizaje_profundo/clase_3/jupyter_notebooks/Clase3_Pytorch_Custom_Loss.ipynb#W3sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Carga del dataset\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Users/juanp_schamun/Documents/GitRepositories/CEIA/aprendizaje_profundo/clase_3/jupyter_notebooks/Clase3_Pytorch_Custom_Loss.ipynb#W3sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m\"\u001b[39;49m\u001b[39m/content/drive/MyDrive/Trabajo AP/Material/class_7_wine_dataset_v2.csv\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
            "File \u001b[1;32md:\\Users\\juanp_schamun\\Documents\\GitRepositories\\CEIA\\aprendizaje_profundo\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    899\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    900\u001b[0m     dialect,\n\u001b[0;32m    901\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    908\u001b[0m     dtype_backend\u001b[39m=\u001b[39mdtype_backend,\n\u001b[0;32m    909\u001b[0m )\n\u001b[0;32m    910\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 912\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
            "File \u001b[1;32md:\\Users\\juanp_schamun\\Documents\\GitRepositories\\CEIA\\aprendizaje_profundo\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    574\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m    576\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 577\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m    579\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[0;32m    580\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
            "File \u001b[1;32md:\\Users\\juanp_schamun\\Documents\\GitRepositories\\CEIA\\aprendizaje_profundo\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1404\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m   1406\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1407\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
            "File \u001b[1;32md:\\Users\\juanp_schamun\\Documents\\GitRepositories\\CEIA\\aprendizaje_profundo\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1659\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[0;32m   1660\u001b[0m         mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m-> 1661\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[0;32m   1662\u001b[0m     f,\n\u001b[0;32m   1663\u001b[0m     mode,\n\u001b[0;32m   1664\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1665\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1666\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[0;32m   1667\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[0;32m   1668\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   1669\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1670\u001b[0m )\n\u001b[0;32m   1671\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1672\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
            "File \u001b[1;32md:\\Users\\juanp_schamun\\Documents\\GitRepositories\\CEIA\\aprendizaje_profundo\\.venv\\Lib\\site-packages\\pandas\\io\\common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    854\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    855\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    856\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    857\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[0;32m    858\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[1;32m--> 859\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[0;32m    860\u001b[0m             handle,\n\u001b[0;32m    861\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[0;32m    862\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[0;32m    863\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m    864\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    865\u001b[0m         )\n\u001b[0;32m    866\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    867\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[0;32m    868\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
            "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/Trabajo AP/Material/class_7_wine_dataset_v2.csv'"
          ]
        }
      ],
      "source": [
        "# Carga del dataset\n",
        "df = pd.read_csv(\"..\\..\\clase_3\\data\\class_7_wine_dataset_v2.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hwnhhYwHk-yf"
      },
      "outputs": [],
      "source": [
        "# Type es tipo categórica, transformamos con One Hot Encoding\n",
        "type_dummies = pd.get_dummies(df['type'], prefix=\"type\")\n",
        "type_dummies\n",
        "df = pd.concat([df,type_dummies], axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oRo9kIhLo-44"
      },
      "outputs": [],
      "source": [
        "# Transformamos quality a quality label\n",
        "df[\"quality_label\"] = df[\"quality\"].apply(lambda q:0 if q<=6 else 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ddfgs8-oqdJh"
      },
      "outputs": [],
      "source": [
        "# Como tenemos pocos nan, borramos las filas donde hay nan y trabajamos con un dataset completo\n",
        "ds = df[df.isna().sum(axis = 1) == 0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "pXT51JETGdIF",
        "outputId": "2a79e417-e272-4de7-a6a4-b45c3b903b0c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Axes: >"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# El dataset está desbalanceado hacia los vinos \"malos\"\n",
        "df[\"quality_label\"].hist()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TmBJD3siinlF"
      },
      "source": [
        "## Armado del dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zE5f2XsqrTr_"
      },
      "outputs": [],
      "source": [
        "# Recordar que debo borrar del dataset de entrada mi columna de salida!\n",
        "x = ds.drop(['Unnamed: 0','type','vendor_id','quality','quality_label'], axis=1) \n",
        "y = ds['quality_label']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oNDPgGUNsvR8"
      },
      "source": [
        "## Normalizacion\n",
        "\n",
        "Las redes neuronales no requieren que los datos esten normalizados, pero la normalización ayuda a que el algoritmo de gradient descent converga más rápido."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N6MXPnges8HE"
      },
      "outputs": [],
      "source": [
        "# Convierto a numpy\n",
        "x = x.to_numpy()\n",
        "y = y.to_numpy()\n",
        "# Normalización min max\n",
        "x_norm = (x - np.min(x, axis=0)) / (np.max(x, axis=0 ) - np.min(x, axis=0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1VVapvoTjvCm"
      },
      "source": [
        "## División del dataset\n",
        "Divido en entrenamiento y validación"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C9dDhJqfyjkE"
      },
      "outputs": [],
      "source": [
        "idx = np.random.permutation(x_norm.shape[0])\n",
        "train_idx = idx[0:int(0.85*len(idx))]\n",
        "valid_idx = idx[int(0.85*len(idx)):]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-VbD8cR8yzD4"
      },
      "outputs": [],
      "source": [
        "train_x = x_norm[train_idx]\n",
        "train_y = y[train_idx]\n",
        "valid_x = x_norm[valid_idx]\n",
        "valid_y = y[valid_idx]\n",
        "\n",
        "n_train = train_x.shape[0]\n",
        "n_valid = valid_x.shape[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bTEFahXrwte2"
      },
      "source": [
        "## Pytorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sCQz7nDkuK7S"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn import metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ducia7gqEBJz",
        "outputId": "82fa92ea-21b1-4cf3-90bc-dd15ebe31814"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'cpu'"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device = \"cpu\"\n",
        "if torch.cuda.is_available():\n",
        "  device = \"cuda:0\"\n",
        "\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "gUpc_S5Fw_Nk"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'Dataset' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32md:\\Users\\juanp_schamun\\Documents\\GitRepositories\\CEIA\\aprendizaje_profundo\\clase_3\\jupyter_notebooks\\Clase3_Pytorch_Custom_Loss.ipynb Cell 19\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Users/juanp_schamun/Documents/GitRepositories/CEIA/aprendizaje_profundo/clase_3/jupyter_notebooks/Clase3_Pytorch_Custom_Loss.ipynb#X24sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Pytorch necesita de una clase de dataset que extienda de torch.utils.data.Dataset\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Users/juanp_schamun/Documents/GitRepositories/CEIA/aprendizaje_profundo/clase_3/jupyter_notebooks/Clase3_Pytorch_Custom_Loss.ipynb#X24sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m# Esta clase dataset debe sobreescribir los métodos init, len y getitem\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Users/juanp_schamun/Documents/GitRepositories/CEIA/aprendizaje_profundo/clase_3/jupyter_notebooks/Clase3_Pytorch_Custom_Loss.ipynb#X24sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mMyDataset\u001b[39;00m(Dataset):\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Users/juanp_schamun/Documents/GitRepositories/CEIA/aprendizaje_profundo/clase_3/jupyter_notebooks/Clase3_Pytorch_Custom_Loss.ipynb#X24sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Users/juanp_schamun/Documents/GitRepositories/CEIA/aprendizaje_profundo/clase_3/jupyter_notebooks/Clase3_Pytorch_Custom_Loss.ipynb#X24sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m   \u001b[39m#__init__ guarda el dataset en una variable de clase\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Users/juanp_schamun/Documents/GitRepositories/CEIA/aprendizaje_profundo/clase_3/jupyter_notebooks/Clase3_Pytorch_Custom_Loss.ipynb#X24sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m   \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, x, y):\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Users/juanp_schamun/Documents/GitRepositories/CEIA/aprendizaje_profundo/clase_3/jupyter_notebooks/Clase3_Pytorch_Custom_Loss.ipynb#X24sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mx \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mfrom_numpy(x\u001b[39m.\u001b[39mastype(\u001b[39m'\u001b[39m\u001b[39mfloat\u001b[39m\u001b[39m'\u001b[39m))  \u001b[39m## Modif JP\u001b[39;00m\n",
            "\u001b[1;31mNameError\u001b[0m: name 'Dataset' is not defined"
          ]
        }
      ],
      "source": [
        "# Pytorch necesita de una clase de dataset que extienda de torch.utils.data.Dataset\n",
        "# Esta clase dataset debe sobreescribir los métodos init, len y getitem\n",
        "class MyDataset(Dataset):\n",
        "\n",
        "  #__init__ guarda el dataset en una variable de clase\n",
        "  def __init__(self, x, y):\n",
        "    self.x = torch.from_numpy(x.astype('float'))  ## Modif JP\n",
        "    self.y = torch.from_numpy(y.astype('float'))  ## Modif JP\n",
        "\n",
        "  # __len__ define el comportamiento de la función len() sobre el objeto\n",
        "  def __len__(self):\n",
        "    return self.x.shape[0]\n",
        "\n",
        "  # __getitem__ define el comportamiento de los []\n",
        "  def __getitem__(self, idx):\n",
        "    return self.x[idx], self.y[idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eGbN4tbtzU6o"
      },
      "outputs": [],
      "source": [
        "# Creo el dataset de entrenamiento\n",
        "train_ds = MyDataset(train_x, train_y)\n",
        "# Creo el dataset de validación\n",
        "valid_ds = MyDataset(valid_x, valid_y)\n",
        "\n",
        "# Pytorch utiliza DataLoader para entregar los dataset de a batches\n",
        "train_dataloader = DataLoader(train_ds, batch_size = 64, shuffle= True)\n",
        "valid_dataloader = DataLoader(valid_ds, batch_size=64)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GoKS1cfjn-oF"
      },
      "source": [
        "#### Entrenamiento con loss estándar (BinaryCrossEntropy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1B95zN1m5r6c"
      },
      "outputs": [],
      "source": [
        "# Arquitectura red neuronal\n",
        "class NNet(torch.nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    # Defino la arquitectura de la red\n",
        "    super().__init__()\n",
        "    self.linear_1 = torch.nn.Linear(in_features=13, out_features=200, bias=True)\n",
        "    self.relu_1 = torch.nn.ReLU()\n",
        "    self.linear_2 = torch.nn.Linear(in_features = 200, out_features=100, bias=True)\n",
        "    self.relu_2 = torch.nn.ReLU()\n",
        "    self.linear_3 = torch.nn.Linear(in_features = 100, out_features= 1, bias=True)\n",
        "    self.output = torch.nn.Sigmoid()\n",
        "\n",
        "  def forward(self, x):\n",
        "    # Defino el cálculo del paso forward\n",
        "    x = self.linear_1(x)\n",
        "    x = self.relu_1(x)\n",
        "    x = self.linear_2(x)\n",
        "    x = self.relu_2(x)\n",
        "    x = self.linear_3(x)\n",
        "    x = self.output(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QLOh2lz4_NXl"
      },
      "outputs": [],
      "source": [
        "# Instanciamos la red\n",
        "nnet = NNet()\n",
        "# Copio la red neuronal al dispositivo donde entrene la red neuronal\n",
        "nnet = nnet.to(device)\n",
        "# Loss\n",
        "loss_function = torch.nn.BCELoss(reduction='sum')\n",
        "# Optimizer\n",
        "optimizer = torch.optim.Adam(nnet.parameters(), lr=0.0001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L9UeuiOmErqk",
        "outputId": "e9dfac0f-1248-473a-ab56-fe2861a9488c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Epoch 0 | Train/Valid loss: 0.650 / 0.594 | Train/Valid accuracy: 0.703 / 0.787 | Train/Valid recall: 0.147 / 0.000 | \n",
            " Epoch 1 | Train/Valid loss: 0.538 / 0.522 | Train/Valid accuracy: 0.806 / 0.787 | Train/Valid recall: 0.000 / 0.000 | \n",
            " Epoch 2 | Train/Valid loss: 0.491 / 0.509 | Train/Valid accuracy: 0.806 / 0.787 | Train/Valid recall: 0.000 / 0.000 | \n",
            " Epoch 3 | Train/Valid loss: 0.479 / 0.501 | Train/Valid accuracy: 0.806 / 0.787 | Train/Valid recall: 0.000 / 0.000 | \n",
            " Epoch 4 | Train/Valid loss: 0.469 / 0.490 | Train/Valid accuracy: 0.806 / 0.787 | Train/Valid recall: 0.000 / 0.000 | \n",
            " Epoch 5 | Train/Valid loss: 0.460 / 0.481 | Train/Valid accuracy: 0.806 / 0.787 | Train/Valid recall: 0.000 / 0.000 | \n",
            " Epoch 6 | Train/Valid loss: 0.450 / 0.470 | Train/Valid accuracy: 0.806 / 0.787 | Train/Valid recall: 0.000 / 0.000 | \n",
            " Epoch 7 | Train/Valid loss: 0.440 / 0.460 | Train/Valid accuracy: 0.806 / 0.787 | Train/Valid recall: 0.000 / 0.000 | \n",
            " Epoch 8 | Train/Valid loss: 0.431 / 0.450 | Train/Valid accuracy: 0.806 / 0.788 | Train/Valid recall: 0.000 / 0.005 | \n",
            " Epoch 9 | Train/Valid loss: 0.424 / 0.444 | Train/Valid accuracy: 0.808 / 0.791 | Train/Valid recall: 0.012 / 0.019 | \n",
            " Epoch 10 | Train/Valid loss: 0.418 / 0.439 | Train/Valid accuracy: 0.810 / 0.797 | Train/Valid recall: 0.030 / 0.048 | \n",
            " Epoch 11 | Train/Valid loss: 0.413 / 0.433 | Train/Valid accuracy: 0.812 / 0.799 | Train/Valid recall: 0.061 / 0.101 | \n",
            " Epoch 12 | Train/Valid loss: 0.409 / 0.430 | Train/Valid accuracy: 0.813 / 0.802 | Train/Valid recall: 0.096 / 0.121 | \n",
            " Epoch 13 | Train/Valid loss: 0.406 / 0.428 | Train/Valid accuracy: 0.816 / 0.802 | Train/Valid recall: 0.141 / 0.121 | \n",
            " Epoch 14 | Train/Valid loss: 0.403 / 0.424 | Train/Valid accuracy: 0.817 / 0.803 | Train/Valid recall: 0.164 / 0.150 | \n",
            " Epoch 15 | Train/Valid loss: 0.402 / 0.422 | Train/Valid accuracy: 0.819 / 0.805 | Train/Valid recall: 0.179 / 0.164 | \n",
            " Epoch 16 | Train/Valid loss: 0.400 / 0.421 | Train/Valid accuracy: 0.818 / 0.804 | Train/Valid recall: 0.195 / 0.155 | \n",
            " Epoch 17 | Train/Valid loss: 0.398 / 0.420 | Train/Valid accuracy: 0.819 / 0.805 | Train/Valid recall: 0.219 / 0.164 | \n",
            " Epoch 18 | Train/Valid loss: 0.397 / 0.417 | Train/Valid accuracy: 0.818 / 0.812 | Train/Valid recall: 0.206 / 0.203 | \n",
            " Epoch 19 | Train/Valid loss: 0.396 / 0.417 | Train/Valid accuracy: 0.819 / 0.811 | Train/Valid recall: 0.233 / 0.193 | \n",
            " Epoch 20 | Train/Valid loss: 0.394 / 0.414 | Train/Valid accuracy: 0.823 / 0.813 | Train/Valid recall: 0.237 / 0.227 | \n",
            " Epoch 21 | Train/Valid loss: 0.394 / 0.413 | Train/Valid accuracy: 0.822 / 0.810 | Train/Valid recall: 0.256 / 0.227 | \n",
            " Epoch 22 | Train/Valid loss: 0.392 / 0.413 | Train/Valid accuracy: 0.823 / 0.808 | Train/Valid recall: 0.255 / 0.208 | \n",
            " Epoch 23 | Train/Valid loss: 0.392 / 0.412 | Train/Valid accuracy: 0.824 / 0.808 | Train/Valid recall: 0.258 / 0.203 | \n",
            " Epoch 24 | Train/Valid loss: 0.390 / 0.413 | Train/Valid accuracy: 0.825 / 0.812 | Train/Valid recall: 0.267 / 0.198 | \n",
            " Epoch 25 | Train/Valid loss: 0.390 / 0.410 | Train/Valid accuracy: 0.825 / 0.810 | Train/Valid recall: 0.253 / 0.217 | \n",
            " Epoch 26 | Train/Valid loss: 0.389 / 0.410 | Train/Valid accuracy: 0.825 / 0.807 | Train/Valid recall: 0.271 / 0.203 | \n",
            " Epoch 27 | Train/Valid loss: 0.389 / 0.408 | Train/Valid accuracy: 0.824 / 0.807 | Train/Valid recall: 0.260 / 0.242 | \n",
            " Epoch 28 | Train/Valid loss: 0.388 / 0.407 | Train/Valid accuracy: 0.825 / 0.805 | Train/Valid recall: 0.271 / 0.237 | \n",
            " Epoch 29 | Train/Valid loss: 0.387 / 0.407 | Train/Valid accuracy: 0.825 / 0.812 | Train/Valid recall: 0.277 / 0.227 | \n",
            " Epoch 30 | Train/Valid loss: 0.387 / 0.407 | Train/Valid accuracy: 0.826 / 0.812 | Train/Valid recall: 0.263 / 0.227 | \n",
            " Epoch 31 | Train/Valid loss: 0.386 / 0.405 | Train/Valid accuracy: 0.824 / 0.805 | Train/Valid recall: 0.271 / 0.251 | \n",
            " Epoch 32 | Train/Valid loss: 0.386 / 0.406 | Train/Valid accuracy: 0.827 / 0.809 | Train/Valid recall: 0.284 / 0.232 | \n",
            " Epoch 33 | Train/Valid loss: 0.385 / 0.407 | Train/Valid accuracy: 0.827 / 0.809 | Train/Valid recall: 0.289 / 0.222 | \n",
            " Epoch 34 | Train/Valid loss: 0.385 / 0.406 | Train/Valid accuracy: 0.825 / 0.809 | Train/Valid recall: 0.274 / 0.222 | \n",
            " Epoch 35 | Train/Valid loss: 0.384 / 0.403 | Train/Valid accuracy: 0.827 / 0.803 | Train/Valid recall: 0.278 / 0.251 | \n",
            " Epoch 36 | Train/Valid loss: 0.384 / 0.404 | Train/Valid accuracy: 0.827 / 0.809 | Train/Valid recall: 0.292 / 0.237 | \n",
            " Epoch 37 | Train/Valid loss: 0.383 / 0.402 | Train/Valid accuracy: 0.828 / 0.806 | Train/Valid recall: 0.274 / 0.275 | \n",
            " Epoch 38 | Train/Valid loss: 0.383 / 0.403 | Train/Valid accuracy: 0.827 / 0.808 | Train/Valid recall: 0.287 / 0.246 | \n",
            " Epoch 39 | Train/Valid loss: 0.383 / 0.404 | Train/Valid accuracy: 0.827 / 0.810 | Train/Valid recall: 0.295 / 0.232 | \n",
            " Epoch 40 | Train/Valid loss: 0.383 / 0.403 | Train/Valid accuracy: 0.828 / 0.811 | Train/Valid recall: 0.290 / 0.246 | \n",
            " Epoch 41 | Train/Valid loss: 0.382 / 0.407 | Train/Valid accuracy: 0.825 / 0.810 | Train/Valid recall: 0.292 / 0.213 | \n",
            " Epoch 42 | Train/Valid loss: 0.382 / 0.403 | Train/Valid accuracy: 0.827 / 0.812 | Train/Valid recall: 0.285 / 0.246 | \n",
            " Epoch 43 | Train/Valid loss: 0.381 / 0.402 | Train/Valid accuracy: 0.827 / 0.811 | Train/Valid recall: 0.296 / 0.251 | \n",
            " Epoch 44 | Train/Valid loss: 0.381 / 0.400 | Train/Valid accuracy: 0.827 / 0.806 | Train/Valid recall: 0.288 / 0.261 | \n",
            " Epoch 45 | Train/Valid loss: 0.381 / 0.402 | Train/Valid accuracy: 0.828 / 0.813 | Train/Valid recall: 0.291 / 0.251 | \n",
            " Epoch 46 | Train/Valid loss: 0.380 / 0.404 | Train/Valid accuracy: 0.827 / 0.811 | Train/Valid recall: 0.305 / 0.222 | \n",
            " Epoch 47 | Train/Valid loss: 0.380 / 0.399 | Train/Valid accuracy: 0.829 / 0.804 | Train/Valid recall: 0.290 / 0.266 | \n",
            " Epoch 48 | Train/Valid loss: 0.380 / 0.400 | Train/Valid accuracy: 0.825 / 0.810 | Train/Valid recall: 0.305 / 0.256 | \n",
            " Epoch 49 | Train/Valid loss: 0.380 / 0.398 | Train/Valid accuracy: 0.827 / 0.807 | Train/Valid recall: 0.291 / 0.271 | \n",
            " Epoch 50 | Train/Valid loss: 0.379 / 0.401 | Train/Valid accuracy: 0.827 / 0.814 | Train/Valid recall: 0.303 / 0.246 | \n",
            " Epoch 51 | Train/Valid loss: 0.379 / 0.400 | Train/Valid accuracy: 0.828 / 0.812 | Train/Valid recall: 0.303 / 0.246 | \n",
            " Epoch 52 | Train/Valid loss: 0.379 / 0.398 | Train/Valid accuracy: 0.828 / 0.805 | Train/Valid recall: 0.297 / 0.266 | \n",
            " Epoch 53 | Train/Valid loss: 0.378 / 0.399 | Train/Valid accuracy: 0.829 / 0.810 | Train/Valid recall: 0.309 / 0.251 | \n",
            " Epoch 54 | Train/Valid loss: 0.378 / 0.397 | Train/Valid accuracy: 0.827 / 0.806 | Train/Valid recall: 0.290 / 0.266 | \n",
            " Epoch 55 | Train/Valid loss: 0.378 / 0.398 | Train/Valid accuracy: 0.827 / 0.809 | Train/Valid recall: 0.304 / 0.256 | \n",
            " Epoch 56 | Train/Valid loss: 0.378 / 0.400 | Train/Valid accuracy: 0.827 / 0.811 | Train/Valid recall: 0.296 / 0.246 | \n",
            " Epoch 57 | Train/Valid loss: 0.377 / 0.397 | Train/Valid accuracy: 0.829 / 0.808 | Train/Valid recall: 0.310 / 0.266 | \n",
            " Epoch 58 | Train/Valid loss: 0.377 / 0.401 | Train/Valid accuracy: 0.827 / 0.814 | Train/Valid recall: 0.309 / 0.242 | \n",
            " Epoch 59 | Train/Valid loss: 0.377 / 0.397 | Train/Valid accuracy: 0.828 / 0.809 | Train/Valid recall: 0.299 / 0.266 | \n",
            " Epoch 60 | Train/Valid loss: 0.377 / 0.395 | Train/Valid accuracy: 0.827 / 0.806 | Train/Valid recall: 0.299 / 0.280 | \n",
            " Epoch 61 | Train/Valid loss: 0.377 / 0.397 | Train/Valid accuracy: 0.828 / 0.809 | Train/Valid recall: 0.311 / 0.256 | \n",
            " Epoch 62 | Train/Valid loss: 0.376 / 0.396 | Train/Valid accuracy: 0.827 / 0.811 | Train/Valid recall: 0.301 / 0.256 | \n",
            " Epoch 63 | Train/Valid loss: 0.376 / 0.394 | Train/Valid accuracy: 0.827 / 0.806 | Train/Valid recall: 0.300 / 0.285 | \n",
            " Epoch 64 | Train/Valid loss: 0.376 / 0.395 | Train/Valid accuracy: 0.828 / 0.806 | Train/Valid recall: 0.312 / 0.271 | \n",
            " Epoch 65 | Train/Valid loss: 0.375 / 0.396 | Train/Valid accuracy: 0.829 / 0.807 | Train/Valid recall: 0.303 / 0.261 | \n",
            " Epoch 66 | Train/Valid loss: 0.375 / 0.395 | Train/Valid accuracy: 0.828 / 0.805 | Train/Valid recall: 0.302 / 0.261 | \n",
            " Epoch 67 | Train/Valid loss: 0.375 / 0.399 | Train/Valid accuracy: 0.828 / 0.816 | Train/Valid recall: 0.318 / 0.246 | \n",
            " Epoch 68 | Train/Valid loss: 0.375 / 0.398 | Train/Valid accuracy: 0.831 / 0.820 | Train/Valid recall: 0.312 / 0.251 | \n",
            " Epoch 69 | Train/Valid loss: 0.375 / 0.393 | Train/Valid accuracy: 0.829 / 0.806 | Train/Valid recall: 0.301 / 0.300 | \n",
            " Epoch 70 | Train/Valid loss: 0.375 / 0.394 | Train/Valid accuracy: 0.829 / 0.809 | Train/Valid recall: 0.309 / 0.261 | \n",
            " Epoch 71 | Train/Valid loss: 0.374 / 0.398 | Train/Valid accuracy: 0.829 / 0.818 | Train/Valid recall: 0.319 / 0.246 | \n",
            " Epoch 72 | Train/Valid loss: 0.375 / 0.392 | Train/Valid accuracy: 0.829 / 0.806 | Train/Valid recall: 0.310 / 0.300 | \n",
            " Epoch 73 | Train/Valid loss: 0.374 / 0.394 | Train/Valid accuracy: 0.831 / 0.811 | Train/Valid recall: 0.313 / 0.261 | \n",
            " Epoch 74 | Train/Valid loss: 0.373 / 0.395 | Train/Valid accuracy: 0.828 / 0.812 | Train/Valid recall: 0.315 / 0.261 | \n",
            " Epoch 75 | Train/Valid loss: 0.373 / 0.394 | Train/Valid accuracy: 0.828 / 0.812 | Train/Valid recall: 0.305 / 0.261 | \n",
            " Epoch 76 | Train/Valid loss: 0.373 / 0.396 | Train/Valid accuracy: 0.829 / 0.819 | Train/Valid recall: 0.317 / 0.261 | \n",
            " Epoch 77 | Train/Valid loss: 0.373 / 0.394 | Train/Valid accuracy: 0.829 / 0.818 | Train/Valid recall: 0.312 / 0.261 | \n",
            " Epoch 78 | Train/Valid loss: 0.373 / 0.397 | Train/Valid accuracy: 0.831 / 0.821 | Train/Valid recall: 0.316 / 0.251 | \n",
            " Epoch 79 | Train/Valid loss: 0.372 / 0.394 | Train/Valid accuracy: 0.830 / 0.818 | Train/Valid recall: 0.313 / 0.261 | \n",
            " Epoch 80 | Train/Valid loss: 0.373 / 0.390 | Train/Valid accuracy: 0.830 / 0.807 | Train/Valid recall: 0.310 / 0.324 | \n",
            " Epoch 81 | Train/Valid loss: 0.372 / 0.391 | Train/Valid accuracy: 0.830 / 0.805 | Train/Valid recall: 0.324 / 0.285 | \n",
            " Epoch 82 | Train/Valid loss: 0.371 / 0.401 | Train/Valid accuracy: 0.831 / 0.818 | Train/Valid recall: 0.332 / 0.217 | \n",
            " Epoch 83 | Train/Valid loss: 0.372 / 0.396 | Train/Valid accuracy: 0.829 / 0.820 | Train/Valid recall: 0.300 / 0.256 | \n",
            " Epoch 84 | Train/Valid loss: 0.371 / 0.391 | Train/Valid accuracy: 0.830 / 0.806 | Train/Valid recall: 0.315 / 0.275 | \n",
            " Epoch 85 | Train/Valid loss: 0.371 / 0.393 | Train/Valid accuracy: 0.829 / 0.814 | Train/Valid recall: 0.319 / 0.261 | \n",
            " Epoch 86 | Train/Valid loss: 0.371 / 0.389 | Train/Valid accuracy: 0.830 / 0.807 | Train/Valid recall: 0.320 / 0.324 | \n",
            " Epoch 87 | Train/Valid loss: 0.371 / 0.392 | Train/Valid accuracy: 0.830 / 0.814 | Train/Valid recall: 0.320 / 0.266 | \n",
            " Epoch 88 | Train/Valid loss: 0.371 / 0.390 | Train/Valid accuracy: 0.830 / 0.810 | Train/Valid recall: 0.316 / 0.280 | \n",
            " Epoch 89 | Train/Valid loss: 0.370 / 0.391 | Train/Valid accuracy: 0.832 / 0.815 | Train/Valid recall: 0.322 / 0.275 | \n",
            " Epoch 90 | Train/Valid loss: 0.370 / 0.388 | Train/Valid accuracy: 0.831 / 0.807 | Train/Valid recall: 0.310 / 0.319 | \n",
            " Epoch 91 | Train/Valid loss: 0.370 / 0.389 | Train/Valid accuracy: 0.829 / 0.808 | Train/Valid recall: 0.320 / 0.300 | \n",
            " Epoch 92 | Train/Valid loss: 0.369 / 0.388 | Train/Valid accuracy: 0.832 / 0.805 | Train/Valid recall: 0.318 / 0.333 | \n",
            " Epoch 93 | Train/Valid loss: 0.369 / 0.392 | Train/Valid accuracy: 0.832 / 0.816 | Train/Valid recall: 0.340 / 0.261 | \n",
            " Epoch 94 | Train/Valid loss: 0.369 / 0.392 | Train/Valid accuracy: 0.831 / 0.819 | Train/Valid recall: 0.321 / 0.261 | \n",
            " Epoch 95 | Train/Valid loss: 0.369 / 0.389 | Train/Valid accuracy: 0.831 / 0.812 | Train/Valid recall: 0.320 / 0.275 | \n",
            " Epoch 96 | Train/Valid loss: 0.369 / 0.389 | Train/Valid accuracy: 0.831 / 0.811 | Train/Valid recall: 0.327 / 0.275 | \n",
            " Epoch 97 | Train/Valid loss: 0.369 / 0.388 | Train/Valid accuracy: 0.832 / 0.811 | Train/Valid recall: 0.319 / 0.280 | \n",
            " Epoch 98 | Train/Valid loss: 0.368 / 0.387 | Train/Valid accuracy: 0.830 / 0.809 | Train/Valid recall: 0.325 / 0.304 | \n",
            " Epoch 99 | Train/Valid loss: 0.368 / 0.395 | Train/Valid accuracy: 0.831 / 0.823 | Train/Valid recall: 0.336 / 0.251 | \n"
          ]
        }
      ],
      "source": [
        "# cantidad de epochs\n",
        "epochs = 100\n",
        "\n",
        "# Doble loop algoritmo Mini-Batch\n",
        "for epoch in range(epochs):\n",
        "  \n",
        "  ############################################\n",
        "  ## Entrenamiento\n",
        "  ############################################\n",
        "  nnet.train(True)\n",
        "\n",
        "  epoch_loss = 0\n",
        "  epoch_y_hat = []\n",
        "  epoch_y = []\n",
        "  \n",
        "  for i,data in enumerate(train_dataloader):\n",
        "    # Obtengo los datos del batch de entrenamiento\n",
        "    x_batch, y_batch = data\n",
        "    # Copio el batch al dispositivo donde entreno la red neuronal\n",
        "    x_batch = x_batch.to(device).float()\n",
        "    y_batch = y_batch.to(device).float().reshape(-1, 1)\n",
        "\n",
        "    # Paso forward\n",
        "    # Limpio optimizer para empezar un nuevo cálculo de gradiente\n",
        "    optimizer.zero_grad()\n",
        "    y_batch_hat = nnet(x_batch)\n",
        "    \n",
        "    # Calculo el loss\n",
        "    loss = loss_function(y_batch_hat, y_batch)\n",
        "\n",
        "    # Backpropagation\n",
        "    loss.backward()\n",
        "\n",
        "    # Actualizar los parámetros\n",
        "    optimizer.step()\n",
        "\n",
        "    # Almaceno los valores reales y mis predicciones para cálcular las métricas\n",
        "    epoch_y += list(y_batch.detach().cpu().numpy())\n",
        "    epoch_y_hat += list(y_batch_hat.detach().cpu().numpy())\n",
        "    # Acumulo la loss del batch\n",
        "    epoch_loss = epoch_loss + loss.item()\n",
        "\n",
        "  # Calculo la media de la loss\n",
        "  epoch_loss = epoch_loss / n_train\n",
        "  # Cálculo la métrica de la epoch\n",
        "  accuracy = metrics.accuracy_score(epoch_y, [j>=0.5 for j in epoch_y_hat])\n",
        "  recall = metrics.recall_score(epoch_y, [j>=0.5 for j in epoch_y_hat])\n",
        "\n",
        "  ############################################\n",
        "  ## Validación\n",
        "  ############################################\n",
        "  # Desactivo el cálculo de gradiente para validación\n",
        "  nnet.train(False)\n",
        "\n",
        "  valid_epoch_loss = 0\n",
        "  valid_epoch_y_hat = []\n",
        "  valid_epoch_y = []\n",
        "\n",
        "  for i,data in enumerate(valid_dataloader):\n",
        "    # Obtengo los datos del batch de validación\n",
        "    x_batch, y_batch = data\n",
        "    # Copio el batch al dispositivo donde entreno la red neuronal\n",
        "    x_batch = x_batch.to(device).float()\n",
        "    y_batch = y_batch.to(device).float().reshape(-1, 1)\n",
        "\n",
        "    # Paso forward\n",
        "    y_batch_hat = nnet(x_batch)\n",
        "    \n",
        "    # Calculo el loss\n",
        "    loss = loss_function(y_batch_hat, y_batch)\n",
        "\n",
        "    # En validación no hago backpropagation!!\n",
        "\n",
        "    # Almaceno los valores reales y mis predicciones para cálcular las métricas\n",
        "    valid_epoch_y += list(y_batch.detach().cpu().numpy())\n",
        "    valid_epoch_y_hat += list(y_batch_hat.detach().cpu().numpy())\n",
        "    # Acumulo la loss del batch\n",
        "    valid_epoch_loss = valid_epoch_loss + loss.item()\n",
        "\n",
        "  # Calculo la media de la loss\n",
        "  valid_epoch_loss = valid_epoch_loss / n_valid\n",
        "  # Cálculo la métrica de la epoch\n",
        "  valid_accuracy = metrics.accuracy_score(valid_epoch_y, [j>=0.5 for j in valid_epoch_y_hat])\n",
        "  valid_recall = metrics.recall_score(valid_epoch_y, [j>=0.5 for j in valid_epoch_y_hat])\n",
        "\n",
        "  ############################################\n",
        "  ## Impresión de resultados por epoch\n",
        "  ############################################\n",
        "  print(f\" Epoch {epoch} | \" \\\n",
        "        f\"Train/Valid loss: {epoch_loss:.3f} / {valid_epoch_loss:.3f} | \" \\\n",
        "        f\"Train/Valid accuracy: {accuracy:.3f} / {valid_accuracy:.3f} | \" \\\n",
        "        f\"Train/Valid recall: {recall:.3f} / {valid_recall:.3f} | \")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hjqN0xV9oL8r"
      },
      "source": [
        "Si bien el accuracy es alto, el recall (que mide el porcentaje de vinos buenos clasificados como buenos) es muy bajo. Esto se debe al desbalance entre las clases "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VHiwQsa0oW54"
      },
      "source": [
        "#### Entrenamiento con loss custom"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qIxq7cfEMY2F"
      },
      "outputs": [],
      "source": [
        "# La función de costo custom se define como la red neuronal, extendiendo la \n",
        "# clase torch.nn.Module\n",
        "class CustomLoss(torch.nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.criterion = torch.nn.BCELoss()\n",
        "    pass\n",
        "\n",
        "  # En el paso forward se aplica el algoritmo de la función de perdida\n",
        "  # y se retorna el valor escalar de pérdida.\n",
        "  def forward(self, output, target):\n",
        "    bce = self.criterion(output, target)\n",
        "    tp = (output * target).sum()\n",
        "    fn = ((1- output) * target).sum()\n",
        "    recall = tp / ((tp + fn))\n",
        "    return bce - recall"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h8I1yic1oc_a"
      },
      "source": [
        "La loss anterior es inventada, es una mezcla de BinaryCrossEntropy y una aproximación con derivada continua del recall. \n",
        "\n",
        "El signo menos antes del recall en el cálculo de la pérdida es porque el algoritmo de optimización busca minimizar la función de pérdida, pero nosotros deseamos maximizar el recall."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j_1DLLpHipbe"
      },
      "outputs": [],
      "source": [
        "# Instanciamos la red\n",
        "nnet = NNet()\n",
        "# Copio la red neuronal al dispositivo donde entrene la red neuronal\n",
        "nnet = nnet.to(device)\n",
        "# Loss custom\n",
        "loss_function = CustomLoss()\n",
        "# Optimizer\n",
        "optimizer = torch.optim.Adam(nnet.parameters(), lr=0.0001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nY5THc5diw_L",
        "outputId": "c6e944d9-2254-4be8-91fc-5a0a0cb4dbc7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Epoch 0 | Train/Valid loss: 0.003 / 0.003 | Train/Valid accuracy: 0.553 / 0.800 | Train/Valid recall: 0.562 / 0.063 | \n",
            " Epoch 1 | Train/Valid loss: 0.003 / 0.003 | Train/Valid accuracy: 0.809 / 0.787 | Train/Valid recall: 0.175 / 0.353 | \n",
            " Epoch 2 | Train/Valid loss: 0.002 / 0.002 | Train/Valid accuracy: 0.777 / 0.759 | Train/Valid recall: 0.482 / 0.541 | \n",
            " Epoch 3 | Train/Valid loss: 0.001 / 0.001 | Train/Valid accuracy: 0.745 / 0.744 | Train/Valid recall: 0.598 / 0.585 | \n",
            " Epoch 4 | Train/Valid loss: 0.000 / -0.000 | Train/Valid accuracy: 0.739 / 0.742 | Train/Valid recall: 0.648 / 0.623 | \n",
            " Epoch 5 | Train/Valid loss: -0.000 / -0.001 | Train/Valid accuracy: 0.745 / 0.753 | Train/Valid recall: 0.665 / 0.614 | \n",
            " Epoch 6 | Train/Valid loss: -0.001 / -0.001 | Train/Valid accuracy: 0.747 / 0.745 | Train/Valid recall: 0.670 / 0.681 | \n",
            " Epoch 7 | Train/Valid loss: -0.001 / -0.001 | Train/Valid accuracy: 0.749 / 0.757 | Train/Valid recall: 0.691 / 0.662 | \n",
            " Epoch 8 | Train/Valid loss: -0.001 / -0.002 | Train/Valid accuracy: 0.749 / 0.756 | Train/Valid recall: 0.696 / 0.671 | \n",
            " Epoch 9 | Train/Valid loss: -0.001 / -0.002 | Train/Valid accuracy: 0.750 / 0.759 | Train/Valid recall: 0.700 / 0.671 | \n",
            " Epoch 10 | Train/Valid loss: -0.002 / -0.002 | Train/Valid accuracy: 0.749 / 0.759 | Train/Valid recall: 0.703 / 0.681 | \n",
            " Epoch 11 | Train/Valid loss: -0.002 / -0.002 | Train/Valid accuracy: 0.751 / 0.762 | Train/Valid recall: 0.697 / 0.686 | \n",
            " Epoch 12 | Train/Valid loss: -0.002 / -0.002 | Train/Valid accuracy: 0.752 / 0.757 | Train/Valid recall: 0.711 / 0.696 | \n",
            " Epoch 13 | Train/Valid loss: -0.002 / -0.002 | Train/Valid accuracy: 0.752 / 0.764 | Train/Valid recall: 0.713 / 0.691 | \n",
            " Epoch 14 | Train/Valid loss: -0.002 / -0.002 | Train/Valid accuracy: 0.752 / 0.762 | Train/Valid recall: 0.725 / 0.696 | \n",
            " Epoch 15 | Train/Valid loss: -0.002 / -0.002 | Train/Valid accuracy: 0.750 / 0.768 | Train/Valid recall: 0.724 / 0.681 | \n",
            " Epoch 16 | Train/Valid loss: -0.002 / -0.002 | Train/Valid accuracy: 0.758 / 0.753 | Train/Valid recall: 0.717 / 0.696 | \n",
            " Epoch 17 | Train/Valid loss: -0.002 / -0.002 | Train/Valid accuracy: 0.748 / 0.757 | Train/Valid recall: 0.727 / 0.686 | \n",
            " Epoch 18 | Train/Valid loss: -0.002 / -0.002 | Train/Valid accuracy: 0.754 / 0.752 | Train/Valid recall: 0.720 / 0.715 | \n",
            " Epoch 19 | Train/Valid loss: -0.002 / -0.002 | Train/Valid accuracy: 0.750 / 0.773 | Train/Valid recall: 0.727 / 0.686 | \n",
            " Epoch 20 | Train/Valid loss: -0.002 / -0.002 | Train/Valid accuracy: 0.751 / 0.774 | Train/Valid recall: 0.733 / 0.676 | \n",
            " Epoch 21 | Train/Valid loss: -0.002 / -0.002 | Train/Valid accuracy: 0.754 / 0.762 | Train/Valid recall: 0.730 / 0.691 | \n",
            " Epoch 22 | Train/Valid loss: -0.002 / -0.002 | Train/Valid accuracy: 0.750 / 0.770 | Train/Valid recall: 0.734 / 0.691 | \n",
            " Epoch 23 | Train/Valid loss: -0.002 / -0.002 | Train/Valid accuracy: 0.757 / 0.758 | Train/Valid recall: 0.735 / 0.691 | \n",
            " Epoch 24 | Train/Valid loss: -0.002 / -0.002 | Train/Valid accuracy: 0.753 / 0.754 | Train/Valid recall: 0.730 / 0.705 | \n",
            " Epoch 25 | Train/Valid loss: -0.002 / -0.002 | Train/Valid accuracy: 0.754 / 0.757 | Train/Valid recall: 0.737 / 0.691 | \n",
            " Epoch 26 | Train/Valid loss: -0.002 / -0.002 | Train/Valid accuracy: 0.751 / 0.756 | Train/Valid recall: 0.730 / 0.691 | \n",
            " Epoch 27 | Train/Valid loss: -0.002 / -0.002 | Train/Valid accuracy: 0.749 / 0.769 | Train/Valid recall: 0.744 / 0.686 | \n",
            " Epoch 28 | Train/Valid loss: -0.002 / -0.002 | Train/Valid accuracy: 0.754 / 0.753 | Train/Valid recall: 0.725 / 0.720 | \n",
            " Epoch 29 | Train/Valid loss: -0.002 / -0.002 | Train/Valid accuracy: 0.755 / 0.766 | Train/Valid recall: 0.739 / 0.691 | \n",
            " Epoch 30 | Train/Valid loss: -0.002 / -0.002 | Train/Valid accuracy: 0.752 / 0.776 | Train/Valid recall: 0.743 / 0.681 | \n",
            " Epoch 31 | Train/Valid loss: -0.002 / -0.002 | Train/Valid accuracy: 0.754 / 0.760 | Train/Valid recall: 0.733 / 0.691 | \n",
            " Epoch 32 | Train/Valid loss: -0.002 / -0.002 | Train/Valid accuracy: 0.753 / 0.766 | Train/Valid recall: 0.743 / 0.691 | \n",
            " Epoch 33 | Train/Valid loss: -0.002 / -0.003 | Train/Valid accuracy: 0.754 / 0.762 | Train/Valid recall: 0.735 / 0.691 | \n",
            " Epoch 34 | Train/Valid loss: -0.002 / -0.003 | Train/Valid accuracy: 0.753 / 0.762 | Train/Valid recall: 0.738 / 0.691 | \n",
            " Epoch 35 | Train/Valid loss: -0.002 / -0.003 | Train/Valid accuracy: 0.754 / 0.765 | Train/Valid recall: 0.741 / 0.681 | \n",
            " Epoch 36 | Train/Valid loss: -0.002 / -0.003 | Train/Valid accuracy: 0.755 / 0.764 | Train/Valid recall: 0.738 / 0.686 | \n",
            " Epoch 37 | Train/Valid loss: -0.002 / -0.003 | Train/Valid accuracy: 0.754 / 0.761 | Train/Valid recall: 0.737 / 0.696 | \n",
            " Epoch 38 | Train/Valid loss: -0.002 / -0.003 | Train/Valid accuracy: 0.757 / 0.763 | Train/Valid recall: 0.730 / 0.696 | \n",
            " Epoch 39 | Train/Valid loss: -0.002 / -0.002 | Train/Valid accuracy: 0.753 / 0.775 | Train/Valid recall: 0.746 / 0.671 | \n",
            " Epoch 40 | Train/Valid loss: -0.002 / -0.003 | Train/Valid accuracy: 0.758 / 0.757 | Train/Valid recall: 0.738 / 0.710 | \n",
            " Epoch 41 | Train/Valid loss: -0.002 / -0.003 | Train/Valid accuracy: 0.753 / 0.772 | Train/Valid recall: 0.745 / 0.676 | \n",
            " Epoch 42 | Train/Valid loss: -0.002 / -0.003 | Train/Valid accuracy: 0.757 / 0.763 | Train/Valid recall: 0.730 / 0.700 | \n",
            " Epoch 43 | Train/Valid loss: -0.002 / -0.003 | Train/Valid accuracy: 0.752 / 0.769 | Train/Valid recall: 0.750 / 0.676 | \n",
            " Epoch 44 | Train/Valid loss: -0.002 / -0.003 | Train/Valid accuracy: 0.758 / 0.766 | Train/Valid recall: 0.743 / 0.681 | \n",
            " Epoch 45 | Train/Valid loss: -0.002 / -0.003 | Train/Valid accuracy: 0.757 / 0.764 | Train/Valid recall: 0.742 / 0.681 | \n",
            " Epoch 46 | Train/Valid loss: -0.002 / -0.003 | Train/Valid accuracy: 0.754 / 0.761 | Train/Valid recall: 0.741 / 0.691 | \n",
            " Epoch 47 | Train/Valid loss: -0.002 / -0.003 | Train/Valid accuracy: 0.755 / 0.773 | Train/Valid recall: 0.741 / 0.676 | \n",
            " Epoch 48 | Train/Valid loss: -0.002 / -0.003 | Train/Valid accuracy: 0.758 / 0.754 | Train/Valid recall: 0.737 / 0.705 | \n",
            " Epoch 49 | Train/Valid loss: -0.002 / -0.003 | Train/Valid accuracy: 0.754 / 0.764 | Train/Valid recall: 0.742 / 0.686 | \n",
            " Epoch 50 | Train/Valid loss: -0.002 / -0.003 | Train/Valid accuracy: 0.756 / 0.772 | Train/Valid recall: 0.742 / 0.681 | \n",
            " Epoch 51 | Train/Valid loss: -0.002 / -0.003 | Train/Valid accuracy: 0.756 / 0.760 | Train/Valid recall: 0.747 / 0.691 | \n",
            " Epoch 52 | Train/Valid loss: -0.002 / -0.003 | Train/Valid accuracy: 0.757 / 0.756 | Train/Valid recall: 0.744 / 0.700 | \n",
            " Epoch 53 | Train/Valid loss: -0.002 / -0.003 | Train/Valid accuracy: 0.754 / 0.757 | Train/Valid recall: 0.745 / 0.691 | \n",
            " Epoch 54 | Train/Valid loss: -0.002 / -0.003 | Train/Valid accuracy: 0.755 / 0.763 | Train/Valid recall: 0.746 / 0.686 | \n",
            " Epoch 55 | Train/Valid loss: -0.002 / -0.003 | Train/Valid accuracy: 0.756 / 0.765 | Train/Valid recall: 0.742 / 0.686 | \n",
            " Epoch 56 | Train/Valid loss: -0.002 / -0.003 | Train/Valid accuracy: 0.756 / 0.753 | Train/Valid recall: 0.744 / 0.700 | \n",
            " Epoch 57 | Train/Valid loss: -0.002 / -0.003 | Train/Valid accuracy: 0.757 / 0.774 | Train/Valid recall: 0.747 / 0.686 | \n",
            " Epoch 58 | Train/Valid loss: -0.002 / -0.003 | Train/Valid accuracy: 0.757 / 0.763 | Train/Valid recall: 0.745 / 0.691 | \n",
            " Epoch 59 | Train/Valid loss: -0.002 / -0.003 | Train/Valid accuracy: 0.756 / 0.756 | Train/Valid recall: 0.740 / 0.691 | \n",
            " Epoch 60 | Train/Valid loss: -0.002 / -0.003 | Train/Valid accuracy: 0.754 / 0.761 | Train/Valid recall: 0.746 / 0.691 | \n",
            " Epoch 61 | Train/Valid loss: -0.003 / -0.003 | Train/Valid accuracy: 0.758 / 0.765 | Train/Valid recall: 0.747 / 0.686 | \n",
            " Epoch 62 | Train/Valid loss: -0.002 / -0.003 | Train/Valid accuracy: 0.759 / 0.759 | Train/Valid recall: 0.742 / 0.691 | \n",
            " Epoch 63 | Train/Valid loss: -0.002 / -0.003 | Train/Valid accuracy: 0.754 / 0.774 | Train/Valid recall: 0.755 / 0.686 | \n",
            " Epoch 64 | Train/Valid loss: -0.003 / -0.003 | Train/Valid accuracy: 0.761 / 0.766 | Train/Valid recall: 0.742 / 0.691 | \n",
            " Epoch 65 | Train/Valid loss: -0.002 / -0.003 | Train/Valid accuracy: 0.756 / 0.757 | Train/Valid recall: 0.747 / 0.691 | \n",
            " Epoch 66 | Train/Valid loss: -0.003 / -0.003 | Train/Valid accuracy: 0.757 / 0.766 | Train/Valid recall: 0.744 / 0.691 | \n",
            " Epoch 67 | Train/Valid loss: -0.003 / -0.003 | Train/Valid accuracy: 0.758 / 0.759 | Train/Valid recall: 0.745 / 0.691 | \n",
            " Epoch 68 | Train/Valid loss: -0.003 / -0.003 | Train/Valid accuracy: 0.757 / 0.760 | Train/Valid recall: 0.741 / 0.691 | \n",
            " Epoch 69 | Train/Valid loss: -0.003 / -0.003 | Train/Valid accuracy: 0.757 / 0.766 | Train/Valid recall: 0.744 / 0.691 | \n",
            " Epoch 70 | Train/Valid loss: -0.003 / -0.003 | Train/Valid accuracy: 0.757 / 0.754 | Train/Valid recall: 0.742 / 0.696 | \n",
            " Epoch 71 | Train/Valid loss: -0.003 / -0.003 | Train/Valid accuracy: 0.757 / 0.753 | Train/Valid recall: 0.744 / 0.691 | \n",
            " Epoch 72 | Train/Valid loss: -0.003 / -0.003 | Train/Valid accuracy: 0.756 / 0.777 | Train/Valid recall: 0.751 / 0.686 | \n",
            " Epoch 73 | Train/Valid loss: -0.003 / -0.003 | Train/Valid accuracy: 0.759 / 0.774 | Train/Valid recall: 0.745 / 0.686 | \n",
            " Epoch 74 | Train/Valid loss: -0.003 / -0.003 | Train/Valid accuracy: 0.758 / 0.778 | Train/Valid recall: 0.742 / 0.686 | \n",
            " Epoch 75 | Train/Valid loss: -0.003 / -0.003 | Train/Valid accuracy: 0.761 / 0.768 | Train/Valid recall: 0.742 / 0.696 | \n",
            " Epoch 76 | Train/Valid loss: -0.003 / -0.003 | Train/Valid accuracy: 0.756 / 0.768 | Train/Valid recall: 0.749 / 0.691 | \n",
            " Epoch 77 | Train/Valid loss: -0.003 / -0.003 | Train/Valid accuracy: 0.762 / 0.762 | Train/Valid recall: 0.742 / 0.691 | \n",
            " Epoch 78 | Train/Valid loss: -0.003 / -0.003 | Train/Valid accuracy: 0.756 / 0.768 | Train/Valid recall: 0.751 / 0.691 | \n",
            " Epoch 79 | Train/Valid loss: -0.003 / -0.003 | Train/Valid accuracy: 0.759 / 0.771 | Train/Valid recall: 0.741 / 0.696 | \n",
            " Epoch 80 | Train/Valid loss: -0.003 / -0.003 | Train/Valid accuracy: 0.759 / 0.764 | Train/Valid recall: 0.744 / 0.696 | \n",
            " Epoch 81 | Train/Valid loss: -0.003 / -0.003 | Train/Valid accuracy: 0.759 / 0.779 | Train/Valid recall: 0.748 / 0.691 | \n",
            " Epoch 82 | Train/Valid loss: -0.003 / -0.003 | Train/Valid accuracy: 0.760 / 0.755 | Train/Valid recall: 0.743 / 0.705 | \n",
            " Epoch 83 | Train/Valid loss: -0.003 / -0.003 | Train/Valid accuracy: 0.759 / 0.757 | Train/Valid recall: 0.739 / 0.696 | \n",
            " Epoch 84 | Train/Valid loss: -0.003 / -0.003 | Train/Valid accuracy: 0.758 / 0.762 | Train/Valid recall: 0.743 / 0.696 | \n",
            " Epoch 85 | Train/Valid loss: -0.003 / -0.003 | Train/Valid accuracy: 0.760 / 0.771 | Train/Valid recall: 0.742 / 0.696 | \n",
            " Epoch 86 | Train/Valid loss: -0.003 / -0.003 | Train/Valid accuracy: 0.766 / 0.758 | Train/Valid recall: 0.745 / 0.705 | \n",
            " Epoch 87 | Train/Valid loss: -0.003 / -0.003 | Train/Valid accuracy: 0.758 / 0.773 | Train/Valid recall: 0.758 / 0.696 | \n",
            " Epoch 88 | Train/Valid loss: -0.003 / -0.003 | Train/Valid accuracy: 0.762 / 0.784 | Train/Valid recall: 0.748 / 0.696 | \n",
            " Epoch 89 | Train/Valid loss: -0.003 / -0.003 | Train/Valid accuracy: 0.765 / 0.762 | Train/Valid recall: 0.751 / 0.700 | \n",
            " Epoch 90 | Train/Valid loss: -0.003 / -0.003 | Train/Valid accuracy: 0.760 / 0.785 | Train/Valid recall: 0.755 / 0.691 | \n",
            " Epoch 91 | Train/Valid loss: -0.003 / -0.003 | Train/Valid accuracy: 0.761 / 0.788 | Train/Valid recall: 0.746 / 0.676 | \n",
            " Epoch 92 | Train/Valid loss: -0.003 / -0.003 | Train/Valid accuracy: 0.767 / 0.762 | Train/Valid recall: 0.742 / 0.696 | \n",
            " Epoch 93 | Train/Valid loss: -0.003 / -0.003 | Train/Valid accuracy: 0.760 / 0.788 | Train/Valid recall: 0.758 / 0.681 | \n",
            " Epoch 94 | Train/Valid loss: -0.003 / -0.003 | Train/Valid accuracy: 0.767 / 0.757 | Train/Valid recall: 0.745 / 0.705 | \n",
            " Epoch 95 | Train/Valid loss: -0.003 / -0.003 | Train/Valid accuracy: 0.764 / 0.774 | Train/Valid recall: 0.748 / 0.700 | \n",
            " Epoch 96 | Train/Valid loss: -0.003 / -0.003 | Train/Valid accuracy: 0.761 / 0.775 | Train/Valid recall: 0.752 / 0.696 | \n",
            " Epoch 97 | Train/Valid loss: -0.003 / -0.003 | Train/Valid accuracy: 0.765 / 0.767 | Train/Valid recall: 0.751 / 0.700 | \n",
            " Epoch 98 | Train/Valid loss: -0.003 / -0.003 | Train/Valid accuracy: 0.764 / 0.779 | Train/Valid recall: 0.749 / 0.700 | \n",
            " Epoch 99 | Train/Valid loss: -0.003 / -0.003 | Train/Valid accuracy: 0.764 / 0.785 | Train/Valid recall: 0.751 / 0.681 | \n"
          ]
        }
      ],
      "source": [
        "# cantidad de epochs\n",
        "epochs = 100\n",
        "\n",
        "# Doble loop algoritmo Mini-Batch\n",
        "for epoch in range(epochs):\n",
        "  \n",
        "  ############################################\n",
        "  ## Entrenamiento\n",
        "  ############################################\n",
        "  nnet.train(True)\n",
        "\n",
        "  epoch_loss = 0\n",
        "  epoch_y_hat = []\n",
        "  epoch_y = []\n",
        "  \n",
        "  for i,data in enumerate(train_dataloader):\n",
        "    # Obtengo los datos del batch de entrenamiento\n",
        "    x_batch, y_batch = data\n",
        "    # Copio el batch al dispositivo donde entreno la red neuronal\n",
        "    x_batch = x_batch.to(device).float()\n",
        "    y_batch = y_batch.to(device).float().reshape(-1, 1)\n",
        "\n",
        "    # Paso forward\n",
        "    # Limpio optimizer para empezar un nuevo cálculo de gradiente\n",
        "    optimizer.zero_grad()\n",
        "    y_batch_hat = nnet(x_batch)\n",
        "    \n",
        "    # Calculo el loss\n",
        "    loss = loss_function(y_batch_hat, y_batch)\n",
        "\n",
        "    # Backpropagation\n",
        "    loss.backward()\n",
        "\n",
        "    # Actualizar los parámetros\n",
        "    optimizer.step()\n",
        "\n",
        "    # Almaceno los valores reales y mis predicciones para cálcular las métricas\n",
        "    epoch_y += list(y_batch.detach().cpu().numpy())\n",
        "    epoch_y_hat += list(y_batch_hat.detach().cpu().numpy())\n",
        "    # Acumulo la loss del batch\n",
        "    epoch_loss = epoch_loss + loss.item()\n",
        "\n",
        "  # Calculo la media de la loss\n",
        "  epoch_loss = epoch_loss / n_train\n",
        "  # Cálculo la métrica de la epoch\n",
        "  accuracy = metrics.accuracy_score(epoch_y, [j>=0.5 for j in epoch_y_hat])\n",
        "  recall = metrics.recall_score(epoch_y, [j>=0.5 for j in epoch_y_hat])\n",
        "\n",
        "  ############################################\n",
        "  ## Validación\n",
        "  ############################################\n",
        "  # Desactivo el cálculo de gradiente para validación\n",
        "  nnet.train(False)\n",
        "\n",
        "  valid_epoch_loss = 0\n",
        "  valid_epoch_y_hat = []\n",
        "  valid_epoch_y = []\n",
        "\n",
        "  for i,data in enumerate(valid_dataloader):\n",
        "    # Obtengo los datos del batch de validación\n",
        "    x_batch, y_batch = data\n",
        "    # Copio el batch al dispositivo donde entreno la red neuronal\n",
        "    x_batch = x_batch.to(device).float()\n",
        "    y_batch = y_batch.to(device).float().reshape(-1, 1)\n",
        "\n",
        "    # Paso forward\n",
        "    y_batch_hat = nnet(x_batch)\n",
        "    \n",
        "    # Calculo el loss\n",
        "    loss = loss_function(y_batch_hat, y_batch)\n",
        "\n",
        "    # En validación no hago backpropagation!!\n",
        "\n",
        "    # Almaceno los valores reales y mis predicciones para cálcular las métricas\n",
        "    valid_epoch_y += list(y_batch.detach().cpu().numpy())\n",
        "    valid_epoch_y_hat += list(y_batch_hat.detach().cpu().numpy())\n",
        "    # Acumulo la loss del batch\n",
        "    valid_epoch_loss = valid_epoch_loss + loss.item()\n",
        "\n",
        "  # Calculo la media de la loss\n",
        "  valid_epoch_loss = valid_epoch_loss / n_valid\n",
        "  # Cálculo la métrica de la epoch\n",
        "  valid_accuracy = metrics.accuracy_score(valid_epoch_y, [j>=0.5 for j in valid_epoch_y_hat])\n",
        "  valid_recall = metrics.recall_score(valid_epoch_y, [j>=0.5 for j in valid_epoch_y_hat])\n",
        "\n",
        "  ############################################\n",
        "  ## Impresión de resultados por epoch\n",
        "  ############################################\n",
        "  print(f\" Epoch {epoch} | \" \\\n",
        "        f\"Train/Valid loss: {epoch_loss:.3f} / {valid_epoch_loss:.3f} | \" \\\n",
        "        f\"Train/Valid accuracy: {accuracy:.3f} / {valid_accuracy:.3f} | \" \\\n",
        "        f\"Train/Valid recall: {recall:.3f} / {valid_recall:.3f} | \")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wxEZFv5Uow37"
      },
      "source": [
        "El accuracy es menor (lo cual es esperable ya que estamos imponiendo restricciones adicionales a la función de costo) pero se logró un recall marcadamente mayor.\n",
        "\n",
        "Con que modelo nos quedamos depende de las necesidades del problema."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
